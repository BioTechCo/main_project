{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. -1 Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from utils.config_helper import update_nested_toml, load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "breast\n",
    "lung\n",
    "prostate\n",
    "stomach\n",
    "rectal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE = input(\"Enter the type of the config file: \")\n",
    "CONFIG_PATH = f\"../config/{TYPE}.toml\"\n",
    "config = load_config(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_nan(df, name):\n",
    "    print(df[pd.isna(df[name])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_file_number = config[\"init\"][\"hyper\"][\"beta_file_number\"]\n",
    "test_ratio = config[\"init\"][\"hyper\"][\"test_ratio\"]\n",
    "seed = config[\"init\"][\"hyper\"][\"splitting_seed\"]\n",
    "normal_number_0 = config[\"init\"][\"hyper\"][\"normal_number_0\"]\n",
    "if beta_file_number == 2:\n",
    "    normal_number_1 = config[\"init\"][\"hyper\"][\"normal_number_1\"]\n",
    "data_source = config[\"init\"][\"hyper\"][\"data_source\"]\n",
    "is_columns_duplicated = config[\"init\"][\"hyper\"][\"is_columns_duplicated\"]\n",
    "is_oversample = config[\"init\"][\"hyper\"][\"is_oversample\"]\n",
    "training_set_path = config[\"init\"][\"hyper\"][\"training_set_path\"]\n",
    "test_set_path = config[\"init\"][\"hyper\"][\"test_set_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on original dataset.\n"
     ]
    }
   ],
   "source": [
    "if is_oversample:\n",
    "    print(\"train on oversampled dataset.\")\n",
    "    trainOutPath = f\"../{TYPE}/result/{data_source}/train{int(100-test_ratio*100)}_oversample\"\n",
    "else:\n",
    "    print(\"train on original dataset.\")\n",
    "    trainOutPath = f\"../{TYPE}/result/{data_source}/train{int(100-test_ratio*100)}\"\n",
    "testOutPath = f\"../{TYPE}/result/{data_source}/test{int(test_ratio*100)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 0 Merge and Split Champ Data\n",
    "- setting is_oversample = 0 to make sure three datasets are stored properly\n",
    "\n",
    "- file paths\n",
    "  - {TYPE}/result/{data_source}/test20/all_beta_normalized_1.csv\n",
    "  - {TYPE}/result/{data_source}/train80/all_beta_normalized_0.csv\n",
    "  - {TYPE}/result/{data_source}/train80_oversample/all_beta_normalized_0_oversample.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1 Merge Dataset (if possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(f\"../{TYPE}/champ_result/{data_source}/all_beta_normalized_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if beta_file_number == 2:\n",
    "    df1 = pd.read_csv(f\"../{TYPE}/champ_result/{data_source}/all_beta_normalized_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "df0\n",
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "df1\n",
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential feature loss\n",
    "if beta_file_number == 2:\n",
    "    feature_name_0 = df0.iloc[:, 0].tolist()\n",
    "    feature_name_1 = df1.iloc[:, 0].tolist()\n",
    "\n",
    "    feature_name = list(set(feature_name_0).intersection(feature_name_1))\n",
    "    update_nested_toml(\n",
    "        \"preprocess.merge_and_split\", \"feature_size_0\", len(feature_name_0)\n",
    "    )\n",
    "    update_nested_toml(\n",
    "        \"preprocess.merge_and_split\", \"feature_size_1\", len(feature_name_1)\n",
    "    )\n",
    "    update_nested_toml(\n",
    "        \"preprocess.merge_and_split\", \"feature_size_intersection\", len(feature_name)\n",
    "    )\n",
    "elif beta_file_number == 1:\n",
    "    feature_name = df0.iloc[:, 0].tolist()\n",
    "    update_nested_toml(\n",
    "        \"preprocess.merge_and_split\", \"feature_size_0\", len(feature_name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if beta_file_number == 2:\n",
    "    df0_join = df0[df0.iloc[:, 0].isin(feature_name)]\n",
    "    df1_join = df1[df1.iloc[:, 0].isin(feature_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if beta_file_number == 2:\n",
    "    df0_join = df0_join.iloc[:, 1::is_columns_duplicated]\n",
    "    if data_source == \"GDC_stomach_GSE99553\":  # god forgive me\n",
    "        df1_join = df1_join.iloc[:, 1::is_columns_duplicated_1]\n",
    "    else:\n",
    "        df1_join = df1_join.iloc[:, 1::is_columns_duplicated]\n",
    "    df0_join.reset_index(drop=True, inplace=True)\n",
    "    df1_join.reset_index(drop=True, inplace=True)\n",
    "    df0_join_normal = df0_join.iloc[:, :normal_number_0]\n",
    "    df0_join_tumor = df0_join.iloc[:, normal_number_0:]\n",
    "    df1_join_normal = df1_join.iloc[:, :normal_number_1]\n",
    "    df1_join_tumor = df1_join.iloc[:, normal_number_1:]\n",
    "elif beta_file_number == 1:\n",
    "    df0_join = df0.iloc[:, 1::is_columns_duplicated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if beta_file_number == 2:\n",
    "    df_normal = pd.concat([df0_join_normal, df1_join_normal], axis=1)\n",
    "    df_tumor = pd.concat([df0_join_tumor, df1_join_tumor], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop those samples with missing value\n",
    "# note: could use padding or other methods to fill the missing value\n",
    "\n",
    "if beta_file_number == 2:\n",
    "    update_nested_toml(\n",
    "        \"preprocess.merge_and_split\", \"Before_dropna_dfn_shape\", df_normal.shape\n",
    "    )\n",
    "    update_nested_toml(\n",
    "        \"preprocess.merge_and_split\", \"Before_dropna_dfc_shape\", df_tumor.shape\n",
    "    )\n",
    "    df_normal.dropna(inplace=True, axis=1)\n",
    "    df_tumor.dropna(inplace=True, axis=1)\n",
    "    update_nested_toml(\n",
    "        \"preprocess.merge_and_split\", \"After_dropna_dfn_shape\", df_normal.shape\n",
    "    )\n",
    "    update_nested_toml(\n",
    "        \"preprocess.merge_and_split\", \"After_dropna_dfc_shape\", df_tumor.shape\n",
    "    )\n",
    "elif beta_file_number == 1:\n",
    "    update_nested_toml(\n",
    "        \"preprocess.merge_and_split\", \"Before_dropna_df_shape\", df0_join.shape\n",
    "    )\n",
    "    df0_join.dropna(inplace=True, axis=1)\n",
    "    update_nested_toml(\n",
    "        \"preprocess.merge_and_split\", \"After_dropna_df_shape\", df0_join.shape\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the normal and tumor data\n",
    "if beta_file_number == 2:\n",
    "    X = pd.concat([df_normal, df_tumor], axis=1).T\n",
    "    y = [0] * df_normal.shape[1] + [1] * df_tumor.shape[1]\n",
    "elif beta_file_number == 1:\n",
    "    X = df0_join.T\n",
    "    y = [0] * normal_number_0 + [1] * (df0_join.shape[1] - normal_number_0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2 Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_ratio, random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.3 Oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_nested_toml(\n",
    "    \"preprocess.merge_and_split\", \"Before_SMOTE_X_train_shape\", X_train.shape\n",
    ")\n",
    "update_nested_toml(\n",
    "    \"preprocess.merge_and_split\", \"Before_SMOTE_y_train_shape\", len(y_train)\n",
    ")\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=seed)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "update_nested_toml(\n",
    "    \"preprocess.merge_and_split\", \"After_SMOTE_X_train_shape\", X_resampled.shape\n",
    ")\n",
    "update_nested_toml(\n",
    "    \"preprocess.merge_and_split\", \"After_SMOTE_y_train_shape\", len(y_resampled)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_distribution_oversample = Counter(y_resampled)\n",
    "train_class_distribution = Counter(y_train)\n",
    "testing_class_distribution = Counter(y_test)\n",
    "\n",
    "update_nested_toml(\"preprocess.merge_and_split\", \"training_set_samples_oversample\", len(X_resampled))\n",
    "update_nested_toml(\"preprocess.merge_and_split\", \"training_set_samples\", len(X_train))\n",
    "update_nested_toml(\"preprocess.merge_and_split\", \"testing_set_samples\", len(X_test))\n",
    "update_nested_toml(\n",
    "    \"preprocess.merge_and_split\",\n",
    "    \"training_class_distribution_oversample\",\n",
    "    [train_class_distribution_oversample[0], train_class_distribution_oversample[1]]\n",
    ")\n",
    "update_nested_toml(\n",
    "    \"preprocess.merge_and_split\",\n",
    "    \"training_class_distribution\",\n",
    "    [train_class_distribution[0], train_class_distribution[1]],\n",
    ")\n",
    "update_nested_toml(\n",
    "    \"preprocess.merge_and_split\",\n",
    "    \"testing_class_distribution\",\n",
    "    [testing_class_distribution[0], testing_class_distribution[1]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled.columns = feature_name\n",
    "X_resampled[\"label\"] = y_resampled\n",
    "X_resampled.sort_values(by=[\"label\"], inplace=True)\n",
    "train_df_os = X_resampled.T\n",
    "train_df_os.columns = range(train_df_os.shape[1])\n",
    "\n",
    "X_train.columns = feature_name\n",
    "X_train[\"label\"] = y_train\n",
    "X_train.sort_values(by=[\"label\"], inplace=True)\n",
    "train_df = X_train.T\n",
    "train_df.columns = range(train_df.shape[1])\n",
    "\n",
    "X_test.columns = feature_name\n",
    "X_test[\"label\"] = y_test\n",
    "X_test.sort_values(by=[\"label\"], inplace=True)\n",
    "test_df = X_test.T\n",
    "test_df.columns = range(test_df.shape[1])\n",
    "\n",
    "train_df_os.insert(0, \"Unnamed: 0\", train_df_os.index)\n",
    "train_df_os.reset_index(drop=True, inplace=True)\n",
    "train_df.insert(0, \"Unnamed: 0\", train_df.index)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.insert(0, \"Unnamed: 0\", test_df.index)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "train_df\n",
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "test_df\n",
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{trainOutPath}\", exist_ok=True)\n",
    "os.makedirs(\n",
    "    f\"{testOutPath}\",\n",
    "    exist_ok=True,\n",
    ")\n",
    "train_df_os.to_csv(f\"{trainOutPath}_oversample/all_beta_normalized_0_oversample.csv\", index=False)\n",
    "train_df.to_csv(f\"{trainOutPath}/all_beta_normalized_0.csv\", index=False)\n",
    "test_df.to_csv(f\"{testOutPath}/all_beta_normalized_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df, test_df, train_df_os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.4 Upload Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_filename = f\"{TYPE}_beta_files.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, \"w\") as zipf:\n",
    "    zipf.write(\n",
    "        f\"{trainOutPath}/all_beta_normalized_0_oversample.csv\",\n",
    "        arcname=\"all_beta_normalized_0_oversample.csv\",\n",
    "    )\n",
    "    zipf.write(\n",
    "        f\"{trainOutPath}/all_beta_normalized_0.csv\", arcname=\"all_beta_normalized_0.csv\"\n",
    "    )\n",
    "    zipf.write(\n",
    "        f\"{testOutPath}/all_beta_normalized_1.csv\", arcname=\"all_beta_normalized_1.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api import utils\n",
    "service = utils.authenticate_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = utils.create_folder(service, TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.run_upload_with_separate_thread(service, directory, zip_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 1 Delta Beta Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = input()\n",
    "\n",
    "output = 'download.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "with zipfile.ZipFile(\"download.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"download\")\n",
    "\n",
    "shutil.move(\"download/all_beta_normalized_0.csv\", f\"all_beta_normalized_0.csv\")\n",
    "shutil.move(\"download/all_beta_normalized_1.csv\", f\"all_beta_normalized_1.csv\")\n",
    "\n",
    "os.remove(\"download.zip\")\n",
    "shutil.rmtree(\"download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Average Delta Beta Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{trainOutPath}/{training_set_path}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outlier in terms of every column\n",
    "def IQR(df):\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    upper_fence = Q3 + IQR * 1.5\n",
    "    lower_fence = Q1 - IQR * 1.5\n",
    "    return upper_fence, lower_fence\n",
    "\n",
    "\n",
    "def no_outlier(df):\n",
    "    upper_fence, lower_fence = IQR(df)\n",
    "    ddf = df[(df > lower_fence) & (df < upper_fence)]\n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(CONFIG_PATH)\n",
    "normal_count = config[\"preprocess\"][\"merge_and_split\"][\"training_class_distribution\"][0]\n",
    "all_beta_normalized_normal = train_df.iloc[:-1, 1 : normal_count + 1 :].T\n",
    "\n",
    "\n",
    "all_beta_normalized_tumor = train_df.iloc[:-1, normal_count + 1 : :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_beta_normalized_normal = no_outlier(all_beta_normalized_normal)\n",
    "all_beta_normalized_tumor = no_outlier(all_beta_normalized_tumor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_avg = all_beta_normalized_normal.mean(skipna=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_beta_normalized_tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_beta_normalized_tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_beta_normalized_tumor = all_beta_normalized_tumor.subtract(\n",
    "    train_normal_avg, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_beta_normalized_tumor = no_outlier(all_beta_normalized_tumor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tumor_mean = all_beta_normalized_tumor.mean(skipna=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_beta = pd.merge(\n",
    "    train_df.iloc[:-1, :1],\n",
    "    pd.DataFrame(train_tumor_mean, columns=[\"dbeta\"]),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "update_nested_toml(\"preprocess.dbeta\", \"delta_beta_avg\", delta_beta.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(delta_beta[pd.isna(delta_beta[\"dbeta\"])])\n",
    "# record the list of feature with dbeta being NaN\n",
    "update_nested_toml(\n",
    "    \"preprocess.dbeta\",\n",
    "    \"NaN_dbeta_feature\",\n",
    "    delta_beta.loc[pd.isna(delta_beta[\"dbeta\"]), \"Unnamed: 0\"].tolist(),\n",
    ")\n",
    "delta_beta.dropna(inplace=True, axis=0)\n",
    "update_nested_toml(\"preprocess.dbeta\", \"delta_beta_avg_remove_NaN\", delta_beta.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmp = pd.read_csv(f\"../{TYPE}/champ_result/{data_source}/DMP_result_0.csv\")\n",
    "dmp = dmp[[\"Unnamed: 0\", \"gene\", \"feature\"]]\n",
    "update_nested_toml(\"preprocess.dbeta\", \"dmp_before_dropna_shape_feature\", dmp.shape[0])\n",
    "dmp.dropna(inplace=True)\n",
    "update_nested_toml(\"preprocess.dbeta\", \"dmp_after_dropna_shape_feature\", dmp.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(delta_beta, dmp, on=\"Unnamed: 0\", how=\"left\")\n",
    "update_nested_toml(\n",
    "    \"preprocess.dbeta\", \"delta_beta_avg_remove_NaN_with_gene_name\", result.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_dBeta_grouped(group):\n",
    "    idx_max = group[\"dbeta\"].abs().idxmax()\n",
    "    return group.loc[idx_max]\n",
    "\n",
    "\n",
    "dbeta = result.groupby(\"gene\", as_index=False).apply(\n",
    "    find_max_dBeta_grouped, include_groups=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta.columns = [\"gene\", \"ID\", \"dbeta\", \"feature\"]\n",
    "dbeta = dbeta[[\"ID\", \"gene\", \"dbeta\", \"feature\"]]\n",
    "# DEBUG\n",
    "dbeta\n",
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comorbidity = pd.read_csv(\n",
    "#     \"../external_result/matchgene174_single_3Y10__OR2.txt\", sep=\"\\t\", header=None\n",
    "# )\n",
    "# dbeta = dbeta[\n",
    "#     dbeta[\"gene\"].isin(comorbidity[0])\n",
    "# ]\n",
    "\n",
    "# result_max_per_gene_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta[\"dbeta\"] = dbeta[\"dbeta\"].apply(lambda x: round(x, 6))\n",
    "dbeta.to_csv(f\"{trainOutPath}/dbeta.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 2 Filter Genes by Average Delta Beta Values\n",
    "1. filter genes by dbeta values\n",
    "3. filter genes by TSS position\n",
    "4. plot distribution of dbeta values\n",
    "5. plot PCA for normal and tumor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Filtering TSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbeta = pd.read_csv(f\"{trainOutPath}/dbeta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSS = dbeta[dbeta[\"feature\"].str.contains(\"TSS\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSS.to_csv(f\"{trainOutPath}/dbeta_TSS.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1\n",
    "TSS_threshold = TSS[abs(TSS[\"dbeta\"]) > threshold]\n",
    "while True:\n",
    "    TSS_threshold = TSS[abs(TSS[\"dbeta\"]) > threshold]\n",
    "    count = TSS_threshold.shape[0]\n",
    "    if (\n",
    "        config[\"preprocess\"][\"filtering\"][\"hyper\"][\"avg_dbeta_lower_bound\"]\n",
    "        <= count\n",
    "        <= config[\"preprocess\"][\"filtering\"][\"hyper\"][\"avg_dbeta_upper_bound\"]\n",
    "    ):\n",
    "        break\n",
    "    threshold -= 0.01\n",
    "threshold = round(threshold, 2)\n",
    "update_nested_toml(\"preprocess.filtering\", \"threshold\", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSS_threshold.to_csv(f\"{trainOutPath}/dbeta_TSS_{threshold}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.kdeplot(TSS_threshold[\"dbeta\"])\n",
    "plt.xlabel(\"delta Beta value\")\n",
    "plt.title(\"Density plot of delta Beta value\")\n",
    "# save the plot\n",
    "plt.savefig(f\"{trainOutPath}/dbeta_TSS_{threshold}.png\")\n",
    "plt.close()\n",
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(f\"{trainOutPath}/all_beta_normalized_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_count = (train_df.iloc[-1, 1:] == 0).sum()\n",
    "df_gene = train_df.iloc[:-1, :]\n",
    "df_gene = df_gene[df_gene[df_gene.columns[0]].isin(dbeta[\"ID\"])]\n",
    "X = df_gene.iloc[:, 1:].reset_index(drop=True).T\n",
    "y = [0 if i < normal_count else 1 for i in range(X.shape[0])]\n",
    "# DEBUG\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {len(y)}\")\n",
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Principal Component 1\": X_pca[:, 0],\n",
    "        \"Principal Component 2\": X_pca[:, 1],\n",
    "        \"Principal Component 3\": X_pca[:, 2],\n",
    "        \"Class\": y,\n",
    "    }\n",
    ")\n",
    "print(df.shape)\n",
    "fig = px.scatter_3d(\n",
    "    df,\n",
    "    x=\"Principal Component 1\",\n",
    "    y=\"Principal Component 2\",\n",
    "    z=\"Principal Component 3\",\n",
    "    color=\"Class\",\n",
    "    title=\"PCA of Dataset\",\n",
    "    color_continuous_scale=\"Viridis\",\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title=\"Principal Component 1\",\n",
    "        yaxis_title=\"Principal Component 2\",\n",
    "        zaxis_title=\"Principal Component 3\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "fig.write_html(f\"{trainOutPath}/preprocess_filtering_pca.html\")\n",
    "\n",
    "# open in browser\n",
    "# save the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 3 feature Selection with ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(CONFIG_PATH)\n",
    "threshold_file = config[\"machine_learning\"][\"hyper\"][\"TSS_threshold\"]\n",
    "\n",
    "TSS_threshold = pd.read_csv(f\"{trainOutPath}/{threshold_file}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSS_threshold_hyper = TSS_threshold[TSS_threshold[\"dbeta\"] > 0]\n",
    "# # DEBUG\n",
    "# TSS_threshold_hyper\n",
    "# # END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if logs/ folder exists\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "from utils.train_helper import TrainHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that there is setup_dbeta in TrainHelper to further cut down the feature size\n",
    "th = TrainHelper(TSS_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Selection (SFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{trainOutPath}/{training_set_path}.csv\")\n",
    "# test_df = pd.read_csv(f\"{testOutPath}/all_beta_normalized_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " th.set_train_test(train_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.set_train_test2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "selection_models = {\n",
    "    \"SVM\": SVC(kernel=\"linear\", random_state=42),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.set_selection_models(selection_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG Training SVM with SFS\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TrainHelper' object has no attribute 'X_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_feature_sfs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTrainOutPath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrainOutPath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_features_to_select\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcluster\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pizza6inch\\main_project\\notebooks\\utils\\train_helper.py:232\u001b[0m, in \u001b[0;36mTrainHelper.select_feature_sfs\u001b[1;34m(self, TrainOutPath, tol, step, n_features_to_select)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    224\u001b[0m     sfs \u001b[38;5;241m=\u001b[39m SequentialFeatureSelector(\n\u001b[0;32m    225\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mselection_model,\n\u001b[0;32m    226\u001b[0m         direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m         n_features_to_select\u001b[38;5;241m=\u001b[39mstep_,\n\u001b[0;32m    231\u001b[0m     )\n\u001b[1;32m--> 232\u001b[0m     sfs\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train)\n\u001b[0;32m    233\u001b[0m     sfs\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test)\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_selected_features(\n\u001b[0;32m    235\u001b[0m         sfs, selection_model_name\n\u001b[0;32m    236\u001b[0m     ) \u001b[38;5;241m>>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_to_file(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTrainOutPath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/sfs/selected_feature_names_sfs.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, is_first_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TrainHelper' object has no attribute 'X_train'"
     ]
    }
   ],
   "source": [
    "th.select_feature_sfs(\n",
    "    TrainOutPath = trainOutPath,\n",
    "    step= 4,\n",
    "    n_features_to_select=\"cluster\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Visualization (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr_tpr_train = pd.read_csv(f\"{trainOutPath}/roc_curve.csv\")\n",
    "# fpr_tpr_test = pd.read_csv(f\"{testOutPath}/roc_curve.csv\")\n",
    "# rfe_train = pd.read_csv(f\"{trainOutPath}/rfe.csv\")\n",
    "# rfe_test = pd.read_csv(f\"{testOutPath}/rfe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfe_j = pd.merge(rfe_train, rfe_test, on=[\"selection_model\", \"train_model\", \"features\"], suffixes=('_train', '_test'))\n",
    "# fpr_tpr_j = pd.merge(fpr_tpr_train, fpr_tpr_test, on=[\"selection_model\", \"train_model\", \"features\"], suffixes=('_train', '_test'))\n",
    "# J = pd.merge(rfe_j, fpr_tpr_j, on=[\"selection_model\", \"train_model\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast\n",
    "\n",
    "# J[\"fpr_train\"] = J[\"fpr_train\"].apply(ast.literal_eval)\n",
    "# J[\"tpr_train\"] = J[\"tpr_train\"].apply(ast.literal_eval)\n",
    "# J[\"fpr_test\"] = J[\"fpr_test\"].apply(ast.literal_eval)\n",
    "# J[\"tpr_test\"] = J[\"tpr_test\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.painter import plot_roc_curve, create_performance_barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# J['accuracy_diff'] = J['accuracy_train'] - J['accuracy_test']\n",
    "# J['recall_diff'] = J['recall_train'] - J['recall_test']\n",
    "# J['f1_score_diff'] = J['f1_score_train'] - J['f1_score_test']\n",
    "# J['AUC_diff'] = J['AUC_train'] - J['AUC_test']\n",
    "# J['MCC_diff'] = J['MCC_train'] - J['MCC_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tweakable width and height\n",
    "# plot_roc_curve(J, \"ROC Curves on Training Set\", f\"{trainOutPath}/roc_train.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tweakable width and height\n",
    "# plot_roc_curve(J, \"ROC Curves on Testing Set\", f\"{testOutPath}/roc_test.html\", mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_acc = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"selection_model\",\n",
    "        \"train_model\",\n",
    "        \"features\",\n",
    "    ]\n",
    ")\n",
    "for i in range(5):\n",
    "    rfe_i = pd.read_csv(f\"{testOutPath}/rfe_{i}.csv\")\n",
    "    rfe_acc = pd.merge(rfe_acc, rfe_i, on=[\"selection_model\", \"train_model\", \"features\"], suffixes=('', f'_{i}'), how='outer')\n",
    "rfe_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Filter Combinations (RFE)\n",
    "\"selection_model\", \"training_model\", and \"features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # eliminate the those with abs accuracy difference greater than 0.1\n",
    "# J = J[abs(J[\"accuracy_diff\"]) < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot difference\n",
    "# performance_metrics = ['accuracy_diff', 'recall_diff', 'f1_score_diff', 'AUC_diff', 'MCC_diff']\n",
    "# ground_by_train_model = J.groupby('train_model')[performance_metrics].mean()\n",
    "# ground_by_train_model['train_model'] = ground_by_train_model.index\n",
    "# ground_by_train_model.to_csv(f\"{trainOutPath}/performance_diff_grouped_by_train_model.csv\", index=False)\n",
    "# color_mapping = {\n",
    "#     \"accuracy_diff\": \"blue\",\n",
    "#     \"recall_diff\": \"red\",\n",
    "#     \"f1_score_diff\": \"green\",\n",
    "#     \"AUC_diff\": \"purple\",\n",
    "#     \"MCC_diff\": \"orange\",\n",
    "# }\n",
    "# create_performance_barchart(\n",
    "#     df=ground_by_train_model,\n",
    "#     color_mapping=color_mapping,\n",
    "#     metric=\"train_model\",\n",
    "#     out_path=f\"{trainOutPath}/performance_diff_grouped_by_train_model.html\",\n",
    "#     title=\"Grouped Performance Difference between Training and Testing Set\",\n",
    "#     x_axis_label=\"Performance Difference (Training - Testing)\",\n",
    "#     y_axis_label=\"Train Model\",\n",
    "#     orientation=\"h\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# J = J[[\"selection_model\", \"train_model\", \"features\", \"accuracy_test\", \"recall_test\", \"f1_score_test\", \"AUC_test\", \"MCC_test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # group by train_model, for each train_model, calculate the mean of each performance metric\n",
    "# performance_metrics = ['accuracy_test', 'recall_test',\n",
    "#                        'f1_score_test', 'AUC_test', 'MCC_test']\n",
    "# ground_by_train_model = J.groupby('train_model')[performance_metrics].mean()\n",
    "# ground_by_train_model['train_model'] = ground_by_train_model.index\n",
    "# ground_by_train_model.to_csv(\n",
    "#     f\"{trainOutPath}/performance_metrics_grouped_by_train_model.csv\", index=False)\n",
    "# color_mapping = {\n",
    "#     \"accuracy_test\": \"blue\",\n",
    "#     \"recall_test\": \"red\",\n",
    "#     \"f1_score_test\": \"green\",\n",
    "#     \"AUC_test\": \"purple\",\n",
    "#     \"MCC_test\": \"orange\",\n",
    "# }\n",
    "# create_performance_barchart(\n",
    "#     df=ground_by_train_model,\n",
    "#     color_mapping=color_mapping,\n",
    "#     metric=\"train_model\",\n",
    "#     out_path=f\"{trainOutPath}/performance_metrics_grouped_by_train_model.html\",\n",
    "#     title=\"Grouped Performance Metrics by Train Model\",\n",
    "#     x_axis_label=\"Performance\",\n",
    "#     y_axis_label=\"Train Model\",\n",
    "#     orientation=\"h\",\n",
    "# )\n",
    "# best_train_model = ground_by_train_model['MCC_test'].idxmax()\n",
    "# print(f\"Best train model: {best_train_model}\")\n",
    "# ground_by_feature = J[J['train_model'] == best_train_model].groupby('features')[\n",
    "#     performance_metrics].mean()\n",
    "# ground_by_feature['features'] = ground_by_feature.index\n",
    "# ground_by_feature.to_csv(\n",
    "#     f\"{trainOutPath}/performance_metrics_grouped_by_feature.csv\", index=False)\n",
    "# create_performance_barchart(\n",
    "#     df=ground_by_feature,\n",
    "#     color_mapping=color_mapping,\n",
    "#     metric=\"features\",\n",
    "#     out_path=f\"{trainOutPath}/performance_metrics_grouped_by_feature.html\",\n",
    "#     title=\"Grouped Performance Metrics by Feature\",\n",
    "#     x_axis_label=\"Performance\",\n",
    "#     y_axis_label=\"Feature\",\n",
    "#     orientation=\"h\",\n",
    "# )\n",
    "# best_num_of_feature = ground_by_feature['MCC_test'].idxmax()\n",
    "# print(f\"Best number of feature: {best_num_of_feature}\")\n",
    "# best_performance_records = J[(J['train_model'] == best_train_model) & (\n",
    "#     J['features'] == best_num_of_feature)]\n",
    "# best_performance_records.to_csv(\n",
    "#     f\"{trainOutPath}/best_performance_records.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first = True\n",
    "# gene_set = set()\n",
    "# with open(f\"{trainOutPath}/selected_feature_names.csv\", \"r\") as f:\n",
    "#     for line in f:\n",
    "#         if first:\n",
    "#             first = False\n",
    "#             continue\n",
    "#         if line.split(\",\")[0].endswith(str(best_num_of_feature)):\n",
    "#             selected_feature_names = line.split(\",\")[1:]\n",
    "#             selected_feature_names[-1] = selected_feature_names[-1].strip()\n",
    "#             gene_set.update(selected_feature_names)\n",
    "\n",
    "# gene_list = pd.DataFrame(list(gene_set), columns=[\"gene\"])\n",
    "# gene_list.to_csv(f\"{trainOutPath}/selected_feature_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Clean Selected Features (SFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_helper import read_selected_features, read_selected_features_json\n",
    "features = read_selected_features(f\"{trainOutPath}/sfs/selected_feature_names_sfs.txt\")\n",
    "th.generate_selected_features(features, f\"{trainOutPath}/sfs/selected_features.json\")\n",
    "read_selected_features_json(f\"{trainOutPath}/sfs/selected_features.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 4 Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 load data\n",
    "\n",
    "remember to calculate distance matrix first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.clustering_helper import hierarchical_clustering, check_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_path = config[\"clustering\"][\"hyper\"][\"dbeta_file\"]\n",
    "gene_set_file = config[\"clustering\"][\"hyper\"][\"gene_set_file\"]\n",
    "bp_file = config[\"clustering\"][\"hyper\"][\"bp_file\"]\n",
    "cc_file = config[\"clustering\"][\"hyper\"][\"cc_file\"]\n",
    "mf_file = config[\"clustering\"][\"hyper\"][\"mf_file\"]\n",
    "terms_count_file = config[\"clustering\"][\"hyper\"][\"terms_count_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_set = pd.read_csv(f\"{trainOutPath}/{gene_set_file}.csv\", index_col=0)\n",
    "distance_matrix_bp = pd.read_csv(f\"{trainOutPath}/{bp_file}.csv\", index_col=0)\n",
    "distance_matrix_cc = pd.read_csv(f\"{trainOutPath}/{cc_file}.csv\", index_col=0)\n",
    "distance_matrix_mf = pd.read_csv(f\"{trainOutPath}/{mf_file}.csv\", index_col=0)\n",
    "terms_count = pd.read_csv(f\"{trainOutPath}/{terms_count_file}.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN with 0\n",
    "distance_matrix_bp = distance_matrix_bp.fillna(0)\n",
    "distance_matrix_cc = distance_matrix_cc.fillna(0)\n",
    "distance_matrix_mf = distance_matrix_mf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex distance matrix\n",
    "index_bp = distance_matrix_bp.index\n",
    "index_cc = distance_matrix_cc.index\n",
    "index_mf = distance_matrix_mf.index\n",
    "index = index_bp.union(index_cc).union(index_mf)\n",
    "distance_matrix_bp_ = distance_matrix_bp.reindex(index=index, columns=index, fill_value=0)\n",
    "distance_matrix_cc_ = distance_matrix_cc.reindex(index=index, columns=index, fill_value=0)\n",
    "distance_matrix_mf_ = distance_matrix_mf.reindex(index=index, columns=index, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a array of distance matrix for each ontology\n",
    "distance_matrix = []\n",
    "\n",
    "distance_matrix.append(distance_matrix_bp_)\n",
    "distance_matrix.append(distance_matrix_cc_)\n",
    "distance_matrix.append(distance_matrix_mf_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Weighted Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [count for count in terms_count[\"count\"]]\n",
    "weight = weight / np.sum(weight)\n",
    "masks = np.array([~np.isnan(distance_matrix[i].values) for i in range(3)])\n",
    "\n",
    "valid_weights = np.array([weight[i] for i in range(3)])[:, None, None] * masks\n",
    "\n",
    "weight_sums = valid_weights.sum(axis=0)\n",
    "\n",
    "normalized_weights = np.divide(valid_weights, weight_sums, where=weight_sums != 0)\n",
    "weighted_sum = sum(\n",
    "    np.nan_to_num(distance_matrix[i].values) * normalized_weights[i] for i in range(3)\n",
    ")\n",
    "\n",
    "\n",
    "weighted_sum_dataframe = pd.DataFrame(weighted_sum, index=index, columns=index)\n",
    "\n",
    "weighted_sum_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result_weighted = hierarchical_clustering(\n",
    "    weighted_sum_dataframe,\n",
    "    range_min=2,\n",
    "    range_max=4,\n",
    "    cluster_number=3,\n",
    "    out_path=f\"{trainOutPath}/hierarchical_clustering_weighted_sum.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = J[[\"selection_model\", \"train_model\", \"features\", \"accuracy_test\", \"recall_test\", \"f1_score_test\", \"AUC_test\", \"MCC_test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by train_model, for each train_model, calculate the mean of each performance metric\n",
    "performance_metrics = ['accuracy_test', 'recall_test',\n",
    "                       'f1_score_test', 'AUC_test', 'MCC_test']\n",
    "ground_by_train_model = J.groupby('train_model')[performance_metrics].mean()\n",
    "ground_by_train_model['train_model'] = ground_by_train_model.index\n",
    "ground_by_train_model.to_csv(\n",
    "    f\"{trainOutPath}/performance_metrics_grouped_by_train_model.csv\", index=False)\n",
    "color_mapping = {\n",
    "    \"accuracy_test\": \"blue\",\n",
    "    \"recall_test\": \"red\",\n",
    "    \"f1_score_test\": \"green\",\n",
    "    \"AUC_test\": \"purple\",\n",
    "    \"MCC_test\": \"orange\",\n",
    "}\n",
    "create_performance_barchart(\n",
    "    df=ground_by_train_model,\n",
    "    color_mapping=color_mapping,\n",
    "    metric=\"train_model\",\n",
    "    out_path=f\"{trainOutPath}/performance_metrics_grouped_by_train_model.html\",\n",
    "    title=\"Grouped Performance Metrics by Train Model\",\n",
    "    x_axis_label=\"Performance\",\n",
    "    y_axis_label=\"Train Model\",\n",
    "    orientation=\"h\",\n",
    ")\n",
    "best_train_model = ground_by_train_model['MCC_test'].idxmax()\n",
    "print(f\"Best train model: {best_train_model}\")\n",
    "ground_by_feature = J[J['train_model'] == best_train_model].groupby('features')[\n",
    "    performance_metrics].mean()\n",
    "ground_by_feature['features'] = ground_by_feature.index\n",
    "ground_by_feature.to_csv(\n",
    "    f\"{trainOutPath}/performance_metrics_grouped_by_feature.csv\", index=False)\n",
    "create_performance_barchart(\n",
    "    df=ground_by_feature,\n",
    "    color_mapping=color_mapping,\n",
    "    metric=\"features\",\n",
    "    out_path=f\"{trainOutPath}/performance_metrics_grouped_by_feature.html\",\n",
    "    title=\"Grouped Performance Metrics by Feature\",\n",
    "    x_axis_label=\"Performance\",\n",
    "    y_axis_label=\"Feature\",\n",
    "    orientation=\"h\",\n",
    ")\n",
    "best_num_of_feature = ground_by_feature['MCC_test'].idxmax()\n",
    "print(f\"Best number of feature: {best_num_of_feature}\")\n",
    "best_performance_records = J[(J['train_model'] == best_train_model) & (\n",
    "    J['features'] == best_num_of_feature)]\n",
    "best_performance_records.to_csv(g\n",
    "    f\"{trainOutPath}/best_performance_records.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "gene_set = set()\n",
    "with open(f\"{trainOutPath}/selected_feature_names.csv\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        if line.split(\",\")[0].endswith(str(best_num_of_feature)):\n",
    "            selected_feature_names = line.split(\",\")[1:]\n",
    "            selected_feature_names[-1] = selected_feature_names[-1].strip()\n",
    "            gene_set.update(selected_feature_names)\n",
    "\n",
    "gene_list = pd.DataFrame(list(gene_set), columns=[\"gene\"])\n",
    "gene_list.to_csv(f\"{trainOutPath}/selected_feature_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 4 Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.clustering_helper import hierarchical_clustering, check_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_path = config[\"clustering\"][\"hyper\"][\"dbeta_file\"]\n",
    "gene_set_file = config[\"clustering\"][\"hyper\"][\"gene_set_file\"]\n",
    "bp_file = config[\"clustering\"][\"hyper\"][\"bp_file\"]\n",
    "cc_file = config[\"clustering\"][\"hyper\"][\"cc_file\"]\n",
    "mf_file = config[\"clustering\"][\"hyper\"][\"mf_file\"]\n",
    "terms_count_file = config[\"clustering\"][\"hyper\"][\"terms_count_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta = pd.read_csv(f\"{trainOutPath}/{dbeta_path}.csv\", index_col=0)\n",
    "gene_set = pd.read_csv(f\"{trainOutPath}/{gene_set_file}.csv\", index_col=0)\n",
    "distance_matrix_bp = pd.read_csv(f\"{trainOutPath}/{bp_file}.csv\", index_col=0)\n",
    "distance_matrix_cc = pd.read_csv(f\"{trainOutPath}/{cc_file}.csv\", index_col=0)\n",
    "distance_matrix_mf = pd.read_csv(f\"{trainOutPath}/{mf_file}.csv\", index_col=0)\n",
    "terms_count = pd.read_csv(f\"{trainOutPath}/{terms_count_file}.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN with 0\n",
    "distance_matrix_bp = distance_matrix_bp.fillna(0)\n",
    "distance_matrix_cc = distance_matrix_cc.fillna(0)\n",
    "distance_matrix_mf = distance_matrix_mf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex distance matrix\n",
    "index_bp = distance_matrix_bp.index\n",
    "index_cc = distance_matrix_cc.index\n",
    "index_mf = distance_matrix_mf.index\n",
    "index = index_bp.union(index_cc).union(index_mf)\n",
    "distance_matrix_bp_ = distance_matrix_bp.reindex(index=index, columns=index, fill_value=0)\n",
    "distance_matrix_cc_ = distance_matrix_cc.reindex(index=index, columns=index, fill_value=0)\n",
    "distance_matrix_mf_ = distance_matrix_mf.reindex(index=index, columns=index, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a array of distance matrix for each ontology\n",
    "distance_matrix = []\n",
    "\n",
    "distance_matrix.append(distance_matrix_bp_)\n",
    "distance_matrix.append(distance_matrix_cc_)\n",
    "distance_matrix.append(distance_matrix_mf_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Weighted Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [count for count in terms_count[\"count\"]]\n",
    "weight = weight / np.sum(weight)\n",
    "masks = np.array([~np.isnan(distance_matrix[i].values) for i in range(3)])\n",
    "\n",
    "valid_weights = np.array([weight[i] for i in range(3)])[:, None, None] * masks\n",
    "\n",
    "weight_sums = valid_weights.sum(axis=0)\n",
    "\n",
    "normalized_weights = np.divide(valid_weights, weight_sums, where=weight_sums != 0)\n",
    "weighted_sum = sum(\n",
    "    np.nan_to_num(distance_matrix[i].values) * normalized_weights[i] for i in range(3)\n",
    ")\n",
    "\n",
    "\n",
    "weighted_sum_dataframe = pd.DataFrame(weighted_sum, index=index, columns=index)\n",
    "\n",
    "weighted_sum_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result_weighted = hierarchical_clustering(\n",
    "    weighted_sum_dataframe,\n",
    "    range_min=2,\n",
    "    range_max=4,\n",
    "    cluster_number=3,\n",
    "    out_path=f\"{trainOutPath}/hierarchical_clustering_weighted_sum.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result_weighted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Simple average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [1, 1, 1]\n",
    "masks = np.array([~np.isnan(distance_matrix[i].values) for i in range(3)])\n",
    "valid_weights = np.array([weight[i] for i in range(3)])[:, None, None] * masks\n",
    "weight_sums = valid_weights.sum(axis=0)\n",
    "normalized_weights = np.divide(valid_weights, weight_sums, where=weight_sums != 0)\n",
    "weighted_sum = sum(\n",
    "    np.nan_to_num(distance_matrix[i].values) * normalized_weights[i] for i in range(3)\n",
    ")\n",
    "simple_sum_dataframe = pd.DataFrame(weighted_sum, index=index, columns=index)\n",
    "simple_sum_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result_simple = hierarchical_clustering(\n",
    "    simple_sum_dataframe,\n",
    "    range_min=2,\n",
    "    range_max=4,\n",
    "    cluster_number=3,\n",
    "    out_path=f\"{trainOutPath}/hierarchical_clustering_simple_sum.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result_simple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Consensus clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_bp = hierarchical_clustering(\n",
    "    distance_matrix_bp, out_path=f\"{trainOutPath}/hierarchical_clustering_bp.png\"\n",
    ")\n",
    "cluster_cc = hierarchical_clustering(\n",
    "    distance_matrix_cc, out_path=f\"{trainOutPath}/hierarchical_clustering_cc.png\"\n",
    ")\n",
    "cluster_mf = hierarchical_clustering(\n",
    "    distance_matrix_mf, out_path=f\"{trainOutPath}/hierarchical_clustering_mf.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_bp.columns = [\"gene\", \"cluster_bp\"]\n",
    "cluster_cc.columns = [\"gene\", \"cluster_cc\"]\n",
    "cluster_mf.columns = [\"gene\", \"cluster_mf\"]\n",
    "cluster_bp_cc = pd.merge(cluster_bp, cluster_cc, on=\"gene\", how=\"outer\")\n",
    "cluster_go = pd.merge(cluster_bp_cc, cluster_mf, on=\"gene\", how=\"outer\")\n",
    "cluster_go = cluster_go.fillna(-1)\n",
    "print(cluster_go.shape)\n",
    "cluster_go.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_genes = cluster_go.shape[0]\n",
    "consensus_matrix = np.zeros((num_genes, num_genes))\n",
    "\n",
    "for i in range(num_genes):\n",
    "    for j in range(i, num_genes):\n",
    "        if cluster_go.iloc[i][\"cluster_bp\"] == cluster_go.iloc[j][\"cluster_bp\"]:\n",
    "            consensus_matrix[i][j] += 1\n",
    "\n",
    "        if cluster_go.iloc[i][\"cluster_cc\"] == cluster_go.iloc[j][\"cluster_cc\"]:\n",
    "            consensus_matrix[i][j] += 1\n",
    "\n",
    "        if cluster_go.iloc[i][\"cluster_mf\"] == cluster_go.iloc[j][\"cluster_mf\"]:\n",
    "            consensus_matrix[i][j] += 1\n",
    "\n",
    "\n",
    "consensus_matrix = pd.DataFrame(\n",
    "    consensus_matrix, index=cluster_go[\"gene\"], columns=cluster_go[\"gene\"]\n",
    ")\n",
    "consensus_matrix += consensus_matrix.T\n",
    "\n",
    "\n",
    "distance_matrix_consensus = 1 - consensus_matrix / 3\n",
    "np.fill_diagonal(distance_matrix_consensus.values, 0)\n",
    "\n",
    "\n",
    "distance_matrix_consensus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result_consensus = hierarchical_clustering(\n",
    "    distance_matrix_consensus,\n",
    "    range_min=2,\n",
    "    range_max=4,\n",
    "    cluster_number=4,\n",
    "    out_path=f\"{trainOutPath}/hierarchical_clustering_consensus.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result_consensus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.clustering_helper import hierarchical_clustering_compare\n",
    "\n",
    "hierarchical_clustering_compare(\n",
    "    [weighted_sum_dataframe, simple_sum_dataframe, distance_matrix_consensus],\n",
    "    [\"Weighted Average\", \"Simple Average\", \"Consensus\"],\n",
    "    out_path=f\"{trainOutPath}/hierarchical_clustering_compare.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta[\"ID\"] = dbeta.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column gene isin weighted_sum_dataframe\n",
    "weighted_dbeta = dbeta[dbeta[\"gene\"].isin(weighted_sum_dataframe.index)]\n",
    "simple_dbeta = dbeta[dbeta[\"gene\"].isin(simple_sum_dataframe.index)]\n",
    "consensus_dbeta = dbeta[dbeta[\"gene\"].isin(distance_matrix_consensus.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_dbeta.merge(cluster_result_weighted, on=\"gene\").to_csv(\n",
    "    f\"{trainOutPath}/{dbeta_path}_weighted.csv\", index=False\n",
    ")\n",
    "simple_dbeta.merge(cluster_result_simple, on=\"gene\").to_csv(\n",
    "    f\"{trainOutPath}/{dbeta_path}_simple.csv\", index=False\n",
    ")\n",
    "consensus_dbeta.merge(cluster_result_consensus, on=\"gene\").to_csv(\n",
    "    f\"{trainOutPath}/{dbeta_path}_consensus.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 5 Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_path = config[\"combination\"][\"hyper\"][\"dbeta_file\"]\n",
    "dbeta = pd.read_csv(f\"{trainOutPath}/{dbeta_path}.csv\")\n",
    "dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list = pd.read_csv(f\"{trainOutPath}/selected_feature_set.csv\")\n",
    "dbeta[dbeta[\"gene\"].isin(gene_list[\"gene\"])].to_csv(\n",
    "    f\"{trainOutPath}/{dbeta_path}_selected.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{trainOutPath}/all_beta_normalized_0.csv\")\n",
    "test_df = pd.read_csv(f\"{testOutPath}/all_beta_normalized_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.combination_helper import CombinationHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = CombinationHelper(\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    dbeta=dbeta,\n",
    "    gene_list=gene_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.setup_dbeta()\n",
    "helper.setup_train_test()\n",
    "helper.setup_combinations()\n",
    "helper.setup_estimators()\n",
    "helper.setup_grids()\n",
    "helper.setup_grid_estimator()\n",
    "helper.setup_grid_estimator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result_weighted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Simple average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [1, 1, 1]\n",
    "masks = np.array([~np.isnan(distance_matrix[i].values) for i in range(3)])\n",
    "valid_weights = np.array([weight[i] for i in range(3)])[:, None, None] * masks\n",
    "weight_sums = valid_weights.sum(axis=0)\n",
    "normalized_weights = np.divide(valid_weights, weight_sums, where=weight_sums != 0)\n",
    "weighted_sum = sum(\n",
    "    np.nan_to_num(distance_matrix[i].values) * normalized_weights[i] for i in range(3)\n",
    ")\n",
    "simple_sum_dataframe = pd.DataFrame(weighted_sum, index=index, columns=index)\n",
    "simple_sum_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result_simple = hierarchical_clustering(\n",
    "    simple_sum_dataframe,\n",
    "    range_min=2,\n",
    "    range_max=4,\n",
    "    cluster_number=3,\n",
    "    out_path=f\"{trainOutPath}/hierarchical_clustering_simple_sum.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result_simple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Consensus clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_bp = hierarchical_clustering(\n",
    "    distance_matrix_bp, out_path=f\"{trainOutPath}/hierarchical_clustering_bp.png\"\n",
    ")\n",
    "cluster_cc = hierarchical_clustering(\n",
    "    distance_matrix_cc, out_path=f\"{trainOutPath}/hierarchical_clustering_cc.png\"\n",
    ")\n",
    "cluster_mf = hierarchical_clustering(\n",
    "    distance_matrix_mf, out_path=f\"{trainOutPath}/hierarchical_clustering_mf.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_bp.columns = [\"gene\", \"cluster_bp\"]\n",
    "cluster_cc.columns = [\"gene\", \"cluster_cc\"]\n",
    "cluster_mf.columns = [\"gene\", \"cluster_mf\"]\n",
    "cluster_bp_cc = pd.merge(cluster_bp, cluster_cc, on=\"gene\", how=\"outer\")\n",
    "cluster_go = pd.merge(cluster_bp_cc, cluster_mf, on=\"gene\", how=\"outer\")\n",
    "cluster_go = cluster_go.fillna(-1)\n",
    "print(cluster_go.shape)\n",
    "cluster_go.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_genes = cluster_go.shape[0]\n",
    "consensus_matrix = np.zeros((num_genes, num_genes))\n",
    "\n",
    "for i in range(num_genes):\n",
    "    for j in range(i, num_genes):\n",
    "        if cluster_go.iloc[i][\"cluster_bp\"] == cluster_go.iloc[j][\"cluster_bp\"]:\n",
    "            consensus_matrix[i][j] += 1\n",
    "\n",
    "        if cluster_go.iloc[i][\"cluster_cc\"] == cluster_go.iloc[j][\"cluster_cc\"]:\n",
    "            consensus_matrix[i][j] += 1\n",
    "\n",
    "        if cluster_go.iloc[i][\"cluster_mf\"] == cluster_go.iloc[j][\"cluster_mf\"]:\n",
    "            consensus_matrix[i][j] += 1\n",
    "\n",
    "\n",
    "consensus_matrix = pd.DataFrame(\n",
    "    consensus_matrix, index=cluster_go[\"gene\"], columns=cluster_go[\"gene\"]\n",
    ")\n",
    "consensus_matrix += consensus_matrix.T\n",
    "\n",
    "\n",
    "distance_matrix_consensus = 1 - consensus_matrix / 3\n",
    "np.fill_diagonal(distance_matrix_consensus.values, 0)\n",
    "\n",
    "\n",
    "distance_matrix_consensus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result_consensus = hierarchical_clustering(\n",
    "    distance_matrix_consensus,\n",
    "    range_min=2,\n",
    "    range_max=4,\n",
    "    cluster_number=4,\n",
    "    out_path=f\"{trainOutPath}/hierarchical_clustering_consensus.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result_consensus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.clustering_helper import hierarchical_clustering_compare\n",
    "\n",
    "hierarchical_clustering_compare(\n",
    "    [weighted_sum_dataframe, simple_sum_dataframe, distance_matrix_consensus],\n",
    "    [\"Weighted Average\", \"Simple Average\", \"Consensus\"],\n",
    "    out_path=f\"{trainOutPath}/hierarchical_clustering_compare.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta[\"ID\"] = dbeta.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column gene isin weighted_sum_dataframe\n",
    "weighted_dbeta = dbeta[dbeta[\"gene\"].isin(weighted_sum_dataframe.index)]\n",
    "simple_dbeta = dbeta[dbeta[\"gene\"].isin(simple_sum_dataframe.index)]\n",
    "consensus_dbeta = dbeta[dbeta[\"gene\"].isin(distance_matrix_consensus.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_dbeta.merge(cluster_result_weighted, on=\"gene\").to_csv(\n",
    "    f\"{trainOutPath}/{dbeta_path}_weighted.csv\", index=False\n",
    ")\n",
    "simple_dbeta.merge(cluster_result_simple, on=\"gene\").to_csv(\n",
    "    f\"{trainOutPath}/{dbeta_path}_simple.csv\", index=False\n",
    ")\n",
    "consensus_dbeta.merge(cluster_result_consensus, on=\"gene\").to_csv(\n",
    "    f\"{trainOutPath}/{dbeta_path}_consensus.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 9 $\\frac{3}{4}$ SimpleModel Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sec. 9 $\\frac{3}{4}$.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_helper import read_selected_features_json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{trainOutPath}/{training_set_path}.csv\")\n",
    "test_df = pd.read_csv(f\"{testOutPath}/{test_set_path}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_dict = read_selected_features_json(f\"{trainOutPath}/sfs/trimmed_selected_features.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_path = config[\"combination\"][\"hyper\"][\"dbeta_file\"]\n",
    "dbeta_info = pd.read_csv(f\"{trainOutPath}/{dbeta_path}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sec. 9 $\\frac{3}{4}$.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_helper import set_parameters\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import json\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "with open(f\"{trainOutPath}/training_param.json\", \"r\") as f:\n",
    "    training_param = json.load(f)\n",
    "\n",
    "xgb_grid = set_parameters(XGBClassifier(random_state=42), training_param[\"XGBoost\"])\n",
    "rf_grid = set_parameters(RandomForestClassifier(random_state=42), training_param[\"RandomForest\"])\n",
    "svm_grid = set_parameters(SVC(random_state=42, probability=True), training_param[\"SVM\"])\n",
    "dt_grid = set_parameters(DecisionTreeClassifier(random_state=42), training_param[\"DecisionTree\"])\n",
    "voting = VotingClassifier(\n",
    "    estimators=[(\"XGBoost\", XGBClassifier(random_state=42)), (\"RandomForest\", RandomForestClassifier(random_state=42)), (\"SVM\", SVC(random_state=42, probability=True)), (\"DecisionTree\", DecisionTreeClassifier(random_state=42))\n",
    "                ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "\n",
    "# comment out the model you don't want to use\n",
    "models = {\n",
    "    \"XGBoost\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": xgb_grid,\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": rf_grid,\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": svm_grid,\n",
    "    },\n",
    "    \"DecisionTree\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": dt_grid,\n",
    "    },\n",
    "    \"Voting\": {\n",
    "        \"is_grid_search\": False,\n",
    "        \"model\": voting,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.simple_model import SimpleModel\n",
    "\n",
    "if not os.path.exists(f\"{trainOutPath}/sfs/\"):\n",
    "    os.makedirs(f\"{trainOutPath}/sfs/\")\n",
    "if not os.path.exists(f\"{testOutPath}/sfs/\"):\n",
    "    os.makedirs(f\"{testOutPath}/sfs/\")\n",
    "\n",
    "for model_name, gene_list in gene_dict.items():\n",
    "    for model_name, model_config in models.items():\n",
    "        model = SimpleModel(\n",
    "            train_df=train_df,\n",
    "            test_df=test_df,\n",
    "            gene_list=gene_list,\n",
    "            dbeta_info=dbeta_info,\n",
    "        )\n",
    "        model.setup_dbeta()\n",
    "        model.setup_train_test()\n",
    "        model.setup_combinations()\n",
    "        model.train(\n",
    "            model_name,\n",
    "            model_config[\"model\"],\n",
    "            f\"{trainOutPath}/sfs/\",\n",
    "            f\"{testOutPath}/sfs/\",\n",
    "            model_config[\"is_grid_search\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 5 Combination (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_path = config[\"combination\"][\"hyper\"][\"dbeta_file\"]\n",
    "dbeta = pd.read_csv(f\"{trainOutPath}/{dbeta_path}.csv\")\n",
    "dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list = pd.read_csv(f\"{trainOutPath}/selected_feature_set.csv\")\n",
    "dbeta[dbeta[\"gene\"].isin(gene_list[\"gene\"])].to_csv(\n",
    "    f\"{trainOutPath}/{dbeta_path}_selected.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{trainOutPath}/all_beta_normalized_0.csv\")\n",
    "test_df = pd.read_csv(f\"{testOutPath}/all_beta_normalized_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.combination_helper import CombinationHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = CombinationHelper(\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    dbeta=dbeta,\n",
    "    gene_list=gene_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.setup_dbeta()\n",
    "helper.setup_train_test()\n",
    "helper.setup_combinations()\n",
    "helper.setup_estimators()\n",
    "helper.setup_grids()\n",
    "helper.setup_grid_estimator()\n",
    "helper.setup_grid_estimator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.train(\n",
    "    train_folder=trainOutPath,\n",
    "    test_folder=testOutPath,\n",
    "    filename=\"combination\",\n",
    "    discard_overfitting=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
