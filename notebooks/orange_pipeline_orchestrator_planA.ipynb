{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. -1 Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from utils.config_helper import update_nested_toml, load_config\n",
    "from utils.process_norm import *\n",
    "os.makedirs(\"logs\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE = input(\"Enter the type of the config file: \")\n",
    "CONFIG_PATH = f\"../config/{TYPE}.toml\"\n",
    "config = load_config(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file_1 = config[\"init\"][\"hyper\"][\"df_file_1\"]\n",
    "df_file_2 = config[\"init\"][\"hyper\"][\"df_file_2\"]\n",
    "dmp_file_1 = config[\"init\"][\"hyper\"][\"dmp_file_1\"]\n",
    "dmp_file_2 = config[\"init\"][\"hyper\"][\"dmp_file_2\"]\n",
    "majority_out_path_1 = config[\"init\"][\"hyper\"][\"majority_out_path_1\"]\n",
    "majority_out_path_2 = config[\"init\"][\"hyper\"][\"majority_out_path_2\"]\n",
    "joined_out_path = config[\"init\"][\"hyper\"][\"joined_out_path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 0 process norm examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Split Dataset Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils.process_norm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the json file\n",
    "cancer_type = input(\"Enter the cancer type: \")\n",
    "with open(f\"../config/{cancer_type}.json\") as f:\n",
    "    J = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = input(\"Enter the raw all_beta_normalized file: \")\n",
    "df = pd.read_csv(J[data_source]['file'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO complement_df feature: 581635\n",
      "INFO complement_df sample (normal, tumor): (39, 39)\n",
      "INFO ratio_df feature: 581635\n",
      "INFO ratio_df sample (normal, tumor): (13, 13)\n"
     ]
    }
   ],
   "source": [
    "dfo = organize_dataset(df, J[data_source][\"normal\"], J[data_source][\"tumor\"], J[data_source][\"sample_count\"])\n",
    "complement_df, ratio_df = split_dataset(dfo, J[data_source][\"split_test\"], J[data_source][\"random_state\"])\n",
    "complement_df.to_csv(\"all_beta_normalized_complement.csv\", index=False)\n",
    "ratio_df.to_csv(\"all_beta_normalized_ratio.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Merge Dataset Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(f\"../stomach/champ_result/gdc_stomach_GSE99553/all_beta_normalized_0.csv\")\n",
    "df1 = pd.read_csv(f\"../stomach/champ_result/gdc_stomach_GSE99553/all_beta_normalized_GSE99553.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = organize_dataset(df0, 2, 395, 2)\n",
    "df1 = organize_dataset(df1, 84, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merge_datasets(df0, df1)\n",
    "merged_df.to_csv(\"merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Inspect NaN Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "df = pd.DataFrame({\n",
    "    'ID': ['A1', 'A2', 'A3', 'A4', 'label'],\n",
    "    'Col1': [1, 2, None, 4, 1],\n",
    "    'Col2': [5, None, 7, 8, 1],\n",
    "    'Col3': [9, 10, 11, 12, 0]\n",
    "})\n",
    "\n",
    "# Column-wise check\n",
    "print(inspect_nan(df, mode=\"column\"))\n",
    "\n",
    "# Row-wise check\n",
    "print(inspect_nan(df, mode=\"row\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 1 Delta Beta Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dbeta_avg_helper import get_dbeta_avg, drop_dbeta_nan, get_dbeta_info\n",
    "\n",
    "os.makedirs(f\"{majority_out_path_1}/section_1\", exist_ok=True)\n",
    "os.makedirs(f\"{majority_out_path_2}/section_1\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(df_file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_beta = get_dbeta_avg(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dbeta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cg00000957</td>\n",
       "      <td>-0.007306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cg00001349</td>\n",
       "      <td>0.012221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cg00001583</td>\n",
       "      <td>0.238457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cg00002028</td>\n",
       "      <td>0.006614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cg00002719</td>\n",
       "      <td>0.293580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353502</th>\n",
       "      <td>cg27656573</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353503</th>\n",
       "      <td>cg27657363</td>\n",
       "      <td>-0.024430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353504</th>\n",
       "      <td>cg27657537</td>\n",
       "      <td>0.008913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353505</th>\n",
       "      <td>cg27662611</td>\n",
       "      <td>0.002383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353506</th>\n",
       "      <td>cg27665648</td>\n",
       "      <td>-0.025981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353507 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     dbeta\n",
       "0       cg00000957 -0.007306\n",
       "1       cg00001349  0.012221\n",
       "2       cg00001583  0.238457\n",
       "3       cg00002028  0.006614\n",
       "4       cg00002719  0.293580\n",
       "...            ...       ...\n",
       "353502  cg27656573  0.001667\n",
       "353503  cg27657363 -0.024430\n",
       "353504  cg27657537  0.008913\n",
       "353505  cg27662611  0.002383\n",
       "353506  cg27665648 -0.025981\n",
       "\n",
       "[353507 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the list of feature with dbeta being NaN\n",
    "delta_beta = drop_dbeta_nan(delta_beta, log_postfix=\"TCGA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmp = pd.read_csv(dmp_file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>gene</th>\n",
       "      <th>dbeta</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cg03630821</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>0.253155</td>\n",
       "      <td>Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cg27394794</td>\n",
       "      <td>A1CF</td>\n",
       "      <td>-0.294116</td>\n",
       "      <td>Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cg07027430</td>\n",
       "      <td>A2BP1</td>\n",
       "      <td>0.328562</td>\n",
       "      <td>Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cg01723761</td>\n",
       "      <td>A2LD1</td>\n",
       "      <td>-0.043872</td>\n",
       "      <td>TSS200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cg11139127</td>\n",
       "      <td>A2M</td>\n",
       "      <td>-0.155606</td>\n",
       "      <td>Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18637</th>\n",
       "      <td>cg03489712</td>\n",
       "      <td>ZYX</td>\n",
       "      <td>-0.144462</td>\n",
       "      <td>TSS1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18638</th>\n",
       "      <td>cg21851534</td>\n",
       "      <td>ZZEF1</td>\n",
       "      <td>0.138291</td>\n",
       "      <td>3'UTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18639</th>\n",
       "      <td>cg10895547</td>\n",
       "      <td>ZZZ3</td>\n",
       "      <td>0.097124</td>\n",
       "      <td>Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18640</th>\n",
       "      <td>cg20009101</td>\n",
       "      <td>psiTPTE22</td>\n",
       "      <td>0.294720</td>\n",
       "      <td>Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18641</th>\n",
       "      <td>cg25020073</td>\n",
       "      <td>tAKR</td>\n",
       "      <td>-0.142959</td>\n",
       "      <td>Body</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18642 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID       gene     dbeta  feature\n",
       "0      cg03630821       A1BG  0.253155     Body\n",
       "1      cg27394794       A1CF -0.294116     Body\n",
       "2      cg07027430      A2BP1  0.328562     Body\n",
       "3      cg01723761      A2LD1 -0.043872   TSS200\n",
       "4      cg11139127        A2M -0.155606     Body\n",
       "...           ...        ...       ...      ...\n",
       "18637  cg03489712        ZYX -0.144462  TSS1500\n",
       "18638  cg21851534      ZZEF1  0.138291    3'UTR\n",
       "18639  cg10895547       ZZZ3  0.097124     Body\n",
       "18640  cg20009101  psiTPTE22  0.294720     Body\n",
       "18641  cg25020073       tAKR -0.142959     Body\n",
       "\n",
       "[18642 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbeta_info = get_dbeta_info(delta_beta, dmp, log_postfix=\"TCGA\")\n",
    "dbeta_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_info[\"dbeta\"] = dbeta_info[\"dbeta\"].apply(lambda x: round(x, 6))\n",
    "dbeta_info.to_csv(f\"{majority_out_path_1}/section_1/dbeta.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(df_file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_beta = get_dbeta_avg(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_beta = drop_dbeta_nan(delta_beta, log_postfix=\"GEO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmp = pd.read_csv(dmp_file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>gene</th>\n",
       "      <th>dbeta</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cg03630821</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>0.045360</td>\n",
       "      <td>Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cg20509831</td>\n",
       "      <td>A1BG-AS1</td>\n",
       "      <td>-0.070945</td>\n",
       "      <td>Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cg11955117</td>\n",
       "      <td>A1CF</td>\n",
       "      <td>-0.144298</td>\n",
       "      <td>Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cg07027430</td>\n",
       "      <td>A2BP1</td>\n",
       "      <td>0.227393</td>\n",
       "      <td>Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cg19815813</td>\n",
       "      <td>A2LD1</td>\n",
       "      <td>-0.058239</td>\n",
       "      <td>TSS200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22551</th>\n",
       "      <td>cg07472835</td>\n",
       "      <td>ZYG11B</td>\n",
       "      <td>-0.098248</td>\n",
       "      <td>Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22552</th>\n",
       "      <td>cg11769486</td>\n",
       "      <td>ZYX</td>\n",
       "      <td>0.090796</td>\n",
       "      <td>ExonBnd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22553</th>\n",
       "      <td>cg16463044</td>\n",
       "      <td>ZZEF1</td>\n",
       "      <td>0.100958</td>\n",
       "      <td>Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22554</th>\n",
       "      <td>cg10895547</td>\n",
       "      <td>ZZZ3</td>\n",
       "      <td>0.038448</td>\n",
       "      <td>Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22555</th>\n",
       "      <td>cg20009101</td>\n",
       "      <td>psiTPTE22</td>\n",
       "      <td>0.134074</td>\n",
       "      <td>Body</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22556 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID       gene     dbeta  feature\n",
       "0      cg03630821       A1BG  0.045360     Body\n",
       "1      cg20509831   A1BG-AS1 -0.070945     Body\n",
       "2      cg11955117       A1CF -0.144298     Body\n",
       "3      cg07027430      A2BP1  0.227393     Body\n",
       "4      cg19815813      A2LD1 -0.058239   TSS200\n",
       "...           ...        ...       ...      ...\n",
       "22551  cg07472835     ZYG11B -0.098248     Body\n",
       "22552  cg11769486        ZYX  0.090796  ExonBnd\n",
       "22553  cg16463044      ZZEF1  0.100958     Body\n",
       "22554  cg10895547       ZZZ3  0.038448     Body\n",
       "22555  cg20009101  psiTPTE22  0.134074     Body\n",
       "\n",
       "[22556 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbeta_info = get_dbeta_info(delta_beta, dmp, log_postfix=\"GEO\")\n",
    "dbeta_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_info[\"dbeta\"] = dbeta_info[\"dbeta\"].apply(lambda x: round(x, 6))\n",
    "dbeta_info.to_csv(f\"{majority_out_path_2}/section_1/dbeta.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 2 Filter Genes by Average Delta Beta Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Filtering TSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{majority_out_path_1}/section_2\", exist_ok=True)\n",
    "os.makedirs(f\"{majority_out_path_2}/section_2\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_info_1 = pd.read_csv(f\"{majority_out_path_1}/section_1/dbeta.csv\")\n",
    "dbeta_info_2 = pd.read_csv(f\"{majority_out_path_2}/section_1/dbeta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSS_1 = dbeta_info_1[dbeta_info_1[\"feature\"].str.contains(\"TSS\")]\n",
    "TSS_2 = dbeta_info_2[dbeta_info_2[\"feature\"].str.contains(\"TSS\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSS_1.to_csv(f\"{majority_out_path_1}/section_2/dbeta_TSS.csv\", index=False)\n",
    "TSS_2.to_csv(f\"{majority_out_path_2}/section_2/dbeta_TSS.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dbeta_avg_helper import detect_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_TSS_threshold_1, threshold_1 = detect_threshold(TSS_1, config=config, log_postfix=\"_TCGA\")\n",
    "dbeta_TSS_threshold_1.to_csv(f\"{majority_out_path_1}/section_2/dbeta_TSS_{threshold_1}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_TSS_threshold_2, threshold_2 = detect_threshold(TSS_2, config=config, log_postfix=\"_GEO\")\n",
    "dbeta_TSS_threshold_2.to_csv(f\"{majority_out_path_2}/section_2/dbeta_TSS_{threshold_2}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dbeta_avg_helper import dbeta_graph, pca_graph\n",
    "\n",
    "dbeta_graph(dbeta_TSS_threshold_1, f\"{majority_out_path_1}/section_2/dbeta_TSS_{threshold_1}.png\")\n",
    "dbeta_graph(dbeta_TSS_threshold_2, f\"{majority_out_path_2}/section_2/dbeta_TSS_{threshold_2}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(df_file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_graph(dbeta_info_1, df_1, f\"{majority_out_path_1}/section_2/pca.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv(df_file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_graph(dbeta_info_2, df_2, f\"{majority_out_path_2}/section_2/pca.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 join dbeta_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{joined_out_path}/section_2\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_info_1 = pd.read_csv(f\"{majority_out_path_1}/section_2/dbeta_TSS_{threshold_1}.csv\")\n",
    "dbeta_info_2 = pd.read_csv(f\"{majority_out_path_2}/section_2/dbeta_TSS_{threshold_2}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(dbeta_info_1, dbeta_info_2, on=\"gene\", how=\"inner\", suffixes=('_TCGA', '_GEO'))\n",
    "merged_df = merged_df[[\"gene\"] + [col for col in merged_df.columns if col != \"gene\"]]\n",
    "merged_df.to_csv(f\"{joined_out_path}/section_2/dbeta_TSS_threshold_joined.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remember to run clustering on the filtered genes first continue to the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 3 Feature Selection with ML (SFS)\n",
    "sequential forward selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember to remove previous results when rerun the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(CONFIG_PATH)\n",
    "\n",
    "train_out_path = config[\"feature_selection\"][\"sfs\"][\"hyper\"][\"train_out_path\"]\n",
    "training_param_file = config[\"feature_selection\"][\"sfs\"][\"hyper\"][\"training_param_file\"]\n",
    "os.makedirs(f\"{train_out_path}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_info_file = config[\"feature_selection\"][\"sfs\"][\"hyper\"][\"dbeta_info_file\"]\n",
    "dbeta_info = pd.read_csv(dbeta_info_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_helper import TrainHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that there is setup_dbeta in TrainHelper to further cut down the feature size\n",
    "th = TrainHelper(dbeta_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(df_file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO Columns with NaNs: {'265': np.float64(1.0)}\n"
     ]
    }
   ],
   "source": [
    "train_df = inspect_nan(train_df, mode=\"column\", remove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.set_train_df(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_models = {\n",
    "    \"SVM\": SVC(kernel=\"linear\", random_state=42),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=50,\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=50,\n",
    "        ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.set_selection_models(selection_models)\n",
    "th.set_train_validate(ID=\"ID_TCGA\", do_validate=False)\n",
    "th.select_feature_sfs(\n",
    "    out_path = f\"{train_out_path}/selected_feature.txt\",\n",
    "    step= 1,\n",
    "    n_features_to_select=\"cluster\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Preparation(second round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(CONFIG_PATH)\n",
    "\n",
    "train_out_path = config[\"feature_selection_2\"][\"sfs\"][\"hyper\"][\"train_out_path\"]\n",
    "training_param_file = config[\"feature_selection_2\"][\"sfs\"][\"hyper\"][\"training_param_file\"]\n",
    "os.makedirs(f\"{train_out_path}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_info_file = config[\"feature_selection_2\"][\"sfs\"][\"hyper\"][\"dbeta_info_file\"]\n",
    "dbeta_info = pd.read_csv(dbeta_info_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_helper import TrainHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that there is setup_dbeta in TrainHelper to further cut down the feature size\n",
    "th = TrainHelper(dbeta_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Selection (second round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(df_file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO Columns with NaNs: {}\n"
     ]
    }
   ],
   "source": [
    "train_df = inspect_nan(train_df, mode=\"column\", remove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.set_train_df(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_models = {\n",
    "    \"SVM\": SVC(kernel=\"linear\", random_state=42),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=50,\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=50,\n",
    "        ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.set_selection_models(selection_models)\n",
    "th.set_train_validate(ID=\"ID_GEO\", do_validate=False)\n",
    "th.select_feature_sfs(\n",
    "    out_path = f\"{train_out_path}/selected_feature.txt\",\n",
    "    step= 1,\n",
    "    n_features_to_select=\"cluster\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 3 Feature Selection with ML (RFE)\n",
    "recursive feature elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember to remove previous results when rerun the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(CONFIG_PATH)\n",
    "\n",
    "train_out_path = config[\"feature_selection\"][\"rfe\"][\"hyper\"][\"train_out_path\"]\n",
    "training_param_file = config[\"feature_selection\"][\"rfe\"][\"hyper\"][\"training_param_file\"]\n",
    "os.makedirs(f\"{train_out_path}\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_info_file = config[\"feature_selection\"][\"rfe\"][\"hyper\"][\"dbeta_info_file\"]\n",
    "TSS_threshold = pd.read_csv(dbeta_info_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_helper import TrainHelper\n",
    "# note that there is setup_dbeta in TrainHelper to further cut down the feature size\n",
    "th = TrainHelper(TSS_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.process_norm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(df_file_1)\n",
    "# validate_df_file = config[\"feature_selection\"][\"hyper\"][\"validate_df_file\"]\n",
    "# validate_df = pd.read_csv(validate_df_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO Columns with NaNs: {'265': np.float64(1.0)}\n"
     ]
    }
   ],
   "source": [
    "train_df = inspect_nan(train_df, mode=\"column\", remove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = inspect_nan(train_df, mode=\"column\", remove=True)\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.set_train_df(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_helper import set_parameters\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# import json\n",
    "\n",
    "# with open(training_param_file, \"r\") as f:\n",
    "#     training_param = json.load(f)\n",
    "# xgb_grid = set_parameters(XGBClassifier(random_state=42), training_param[\"XGBoost\"])\n",
    "# rf_grid = set_parameters(\n",
    "#     RandomForestClassifier(random_state=42), training_param[\"RandomForest\"]\n",
    "# )\n",
    "# svm_grid = set_parameters(SVC(random_state=42, probability=True), training_param[\"SVM\"])\n",
    "# dt_grid = set_parameters(\n",
    "#     DecisionTreeClassifier(random_state=42), training_param[\"DecisionTree\"]\n",
    "# )\n",
    "\n",
    "# train_models = {\n",
    "#     \"XGBoost\": xgb_grid,\n",
    "#     \"RandomForest\": rf_grid,\n",
    "#     \"SVM\": svm_grid,\n",
    "#     \"DecisionTree\": dt_grid,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_models = {\n",
    "    \"SVM\": SVC(kernel=\"linear\", random_state=42),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=50,\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=50,\n",
    "        ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.set_selection_models(selection_models)\n",
    "# th.set_grid_estimators(train_models)\n",
    "th.set_train_validate(ID=\"ID_TCGA\", do_validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO Training SVM with RFE\n",
      "INFO Training SVM with 3 clusters selected\n",
      "INFO Training finished with 4 clusters selected\n",
      "INFO Training DecisionTree with RFE\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training finished with 4 clusters selected\n",
      "INFO Training LogisticRegression with RFE\n",
      "INFO Training LogisticRegression with 2 clusters selected\n",
      "INFO Training LogisticRegression with 2 clusters selected\n",
      "INFO Training LogisticRegression with 2 clusters selected\n",
      "INFO Training LogisticRegression with 2 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training finished with 4 clusters selected\n",
      "INFO Training RandomForest with RFE\n",
      "INFO Training RandomForest with 2 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training finished with 4 clusters selected\n",
      "INFO Training XGBoost with RFE\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training finished with 4 clusters selected\n"
     ]
    }
   ],
   "source": [
    "th.select_feature_rfe(\n",
    "    train_out_path = train_out_path,\n",
    "    selected_feature_path = f\"{train_out_path}/selected_feature.txt\",\n",
    "    feature_range = \"cluster\",\n",
    "    do_validation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Preparation (second round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(CONFIG_PATH)\n",
    "\n",
    "train_out_path = config[\"feature_selection_2\"][\"rfe\"][\"hyper\"][\"train_out_path\"]\n",
    "training_param_file = config[\"feature_selection_2\"][\"rfe\"][\"hyper\"][\"training_param_file\"]\n",
    "os.makedirs(f\"{train_out_path}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_info_file = config[\"feature_selection\"][\"rfe\"][\"hyper\"][\"dbeta_info_file\"]\n",
    "TSS_threshold = pd.read_csv(dbeta_info_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_helper import TrainHelper\n",
    "# note that there is setup_dbeta in TrainHelper to further cut down the feature size\n",
    "th = TrainHelper(TSS_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Selection (second round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(df_file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.set_train_df(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_models = {\n",
    "    \"SVM\": SVC(kernel=\"linear\", random_state=42),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=50,\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=50,\n",
    "        ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.set_selection_models(selection_models)\n",
    "# th.set_grid_estimators(train_models)\n",
    "th.set_train_validate(ID=\"ID_GEO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO Training SVM with RFE\n",
      "INFO Training SVM with 2 clusters selected\n",
      "INFO Training SVM with 2 clusters selected\n",
      "INFO Training SVM with 3 clusters selected\n",
      "INFO Training SVM with 3 clusters selected\n",
      "INFO Training SVM with 3 clusters selected\n",
      "INFO Training SVM with 3 clusters selected\n",
      "INFO Training SVM with 3 clusters selected\n",
      "INFO Training SVM with 3 clusters selected\n",
      "INFO Training SVM with 3 clusters selected\n",
      "INFO Training SVM with 3 clusters selected\n",
      "INFO Training SVM with 3 clusters selected\n",
      "INFO Training SVM with 3 clusters selected\n",
      "INFO Training SVM with 3 clusters selected\n",
      "INFO Training SVM with 3 clusters selected\n",
      "INFO Training SVM with 3 clusters selected\n",
      "INFO Training finished with 4 clusters selected\n",
      "INFO Training DecisionTree with RFE\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 2 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training DecisionTree with 3 clusters selected\n",
      "INFO Training finished with 4 clusters selected\n",
      "INFO Training LogisticRegression with RFE\n",
      "INFO Training LogisticRegression with 2 clusters selected\n",
      "INFO Training LogisticRegression with 2 clusters selected\n",
      "INFO Training LogisticRegression with 2 clusters selected\n",
      "INFO Training LogisticRegression with 2 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training LogisticRegression with 3 clusters selected\n",
      "INFO Training finished with 4 clusters selected\n",
      "INFO Training RandomForest with RFE\n",
      "INFO Training RandomForest with 2 clusters selected\n",
      "INFO Training RandomForest with 2 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training RandomForest with 3 clusters selected\n",
      "INFO Training finished with 4 clusters selected\n",
      "INFO Training XGBoost with RFE\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 2 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training XGBoost with 3 clusters selected\n",
      "INFO Training finished with 4 clusters selected\n"
     ]
    }
   ],
   "source": [
    "th.select_feature_rfe(\n",
    "    train_out_path = train_out_path,\n",
    "    selected_feature_path = f\"{train_out_path}/selected_feature.txt\",\n",
    "    feature_range = \"cluster\",\n",
    "    do_validation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 4 Clean Selected Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Generate Feature json for SimpleModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'SVM': ['FOXD2', 'GFRA2', 'GHSR', 'MIR196A2', 'SCT'],\n",
       "             'DecisionTree': ['ALX1',\n",
       "              'GHITM',\n",
       "              'KRTAP20-1',\n",
       "              'NEFM',\n",
       "              'PRLHR',\n",
       "              'MIR654'],\n",
       "             'LogisticRegression': ['ALX1',\n",
       "              'FOXD2',\n",
       "              'ATP5G2',\n",
       "              'TAC1',\n",
       "              'GFRA2',\n",
       "              'MIR196A2'],\n",
       "             'RandomForest': ['ALX1',\n",
       "              'FOXD2',\n",
       "              'CA3',\n",
       "              'FRZB',\n",
       "              'MIR1197',\n",
       "              'GFRA2'],\n",
       "             'XGBoost': ['ALX1',\n",
       "              'FOXD2',\n",
       "              'POU3F3',\n",
       "              'CCDC8',\n",
       "              'GFRA2',\n",
       "              'MIR654']})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.train_helper import read_selected_features, read_selected_features_json, TrainHelper\n",
    "config = load_config(CONFIG_PATH)\n",
    "dbeta_info_file = config[\"feature_selection\"][\"rfe\"][\"hyper\"][\"dbeta_info_file\"]\n",
    "dbeta_info = pd.read_csv(dbeta_info_file)\n",
    "th = TrainHelper(dbeta_info)\n",
    "method = \"rfe\"\n",
    "features = read_selected_features(f\"{majority_out_path_1}/section_3/{method}/selected_feature.txt\")\n",
    "th.generate_selected_features(\n",
    "    features,\n",
    "    f\"{majority_out_path_1}/section_3/{method}/selected_features.json\",\n",
    "    mode=\"min\",\n",
    "    out_format=\"json\",\n",
    ")\n",
    "\n",
    "read_selected_features_json(f\"{majority_out_path_1}/section_3/{method}/selected_features.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'SVM': ['DBC1', 'DEGS1', 'TRIM59', 'FOXB2', 'GRIK3', 'MIR129-2'],\n",
       "             'DecisionTree': ['CA3',\n",
       "              'NID2',\n",
       "              'TRIM59',\n",
       "              'ZSCAN18',\n",
       "              'PRLHR',\n",
       "              'MIR654'],\n",
       "             'LogisticRegression': ['DGKI',\n",
       "              'HMGCL',\n",
       "              'TRIM59',\n",
       "              'FOXB2',\n",
       "              'MIR129-2',\n",
       "              'GRIK3'],\n",
       "             'RandomForest': ['DGKI',\n",
       "              'SUB1',\n",
       "              'TRIM59',\n",
       "              'FOXB2',\n",
       "              'MIR124-2',\n",
       "              'KCNK2'],\n",
       "             'XGBoost': ['FOXB2',\n",
       "              'NID2',\n",
       "              'SUB1',\n",
       "              'TRIM59',\n",
       "              'MIR124-2',\n",
       "              'PRLHR']})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.train_helper import read_selected_features, read_selected_features_json, TrainHelper\n",
    "config = load_config(CONFIG_PATH)\n",
    "dbeta_info_file = config[\"feature_selection_2\"][\"rfe\"][\"hyper\"][\"dbeta_info_file\"]\n",
    "dbeta_info = pd.read_csv(dbeta_info_file)\n",
    "th = TrainHelper(dbeta_info)\n",
    "method = \"rfe\"\n",
    "features = read_selected_features(f\"{majority_out_path_2}/section_3/{method}/selected_feature.txt\")\n",
    "th.generate_selected_features(\n",
    "    features,\n",
    "    f\"{majority_out_path_2}/section_3/{method}/selected_features.json\",\n",
    "    mode=\"min\",\n",
    "    out_format=\"json\",\n",
    ")\n",
    "\n",
    "# use this to read json\n",
    "read_selected_features_json(f\"{majority_out_path_2}/section_3/{method}/selected_features.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 5 Clustering Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. load data\n",
    "\n",
    "remember to calculate distance matrix first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.clustering_helper import hierarchical_clustering, check_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_prefix = config[\"clustering_visual\"][\"hyper\"][\"result_prefix\"]\n",
    "dbeta_file = config[\"clustering_visual\"][\"hyper\"][\"dbeta_file\"]\n",
    "bp_file = config[\"clustering_visual\"][\"hyper\"][\"bp_file\"]\n",
    "cc_file = config[\"clustering_visual\"][\"hyper\"][\"cc_file\"]\n",
    "mf_file = config[\"clustering_visual\"][\"hyper\"][\"mf_file\"]\n",
    "terms_count_file = config[\"clustering_visual\"][\"hyper\"][\"terms_count_file\"]\n",
    "result_out_path = config[\"clustering_visual\"][\"hyper\"][\"result_out_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(result_out_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_set = pd.read_csv(dbeta_file, index_col=0)\n",
    "distance_matrix_bp = pd.read_csv(bp_file, index_col=0)\n",
    "distance_matrix_cc = pd.read_csv(cc_file, index_col=0)\n",
    "distance_matrix_mf = pd.read_csv(mf_file, index_col=0)\n",
    "terms_count = pd.read_csv(terms_count_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN with 0\n",
    "distance_matrix_bp = distance_matrix_bp.fillna(0)\n",
    "distance_matrix_cc = distance_matrix_cc.fillna(0)\n",
    "distance_matrix_mf = distance_matrix_mf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex distance matrix\n",
    "index_bp = distance_matrix_bp.index\n",
    "index_cc = distance_matrix_cc.index\n",
    "index_mf = distance_matrix_mf.index\n",
    "index = index_bp.union(index_cc).union(index_mf)\n",
    "distance_matrix_bp_ = distance_matrix_bp.reindex(index=index, columns=index, fill_value=0)\n",
    "distance_matrix_cc_ = distance_matrix_cc.reindex(index=index, columns=index, fill_value=0)\n",
    "distance_matrix_mf_ = distance_matrix_mf.reindex(index=index, columns=index, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a array of distance matrix for each ontology\n",
    "distance_matrix = []\n",
    "\n",
    "distance_matrix.append(distance_matrix_bp_)\n",
    "distance_matrix.append(distance_matrix_cc_)\n",
    "distance_matrix.append(distance_matrix_mf_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Weighted Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADAMTS20</th>\n",
       "      <th>ADCY4</th>\n",
       "      <th>AIP</th>\n",
       "      <th>ALX1</th>\n",
       "      <th>ALX4</th>\n",
       "      <th>ATG16L1</th>\n",
       "      <th>ATP5G2</th>\n",
       "      <th>C1orf114</th>\n",
       "      <th>CA3</th>\n",
       "      <th>CCDC8</th>\n",
       "      <th>...</th>\n",
       "      <th>TAC1</th>\n",
       "      <th>TMEM196</th>\n",
       "      <th>TRIM59</th>\n",
       "      <th>TUBB6</th>\n",
       "      <th>WDR8</th>\n",
       "      <th>WNT3</th>\n",
       "      <th>ZC3H12D</th>\n",
       "      <th>ZFP42</th>\n",
       "      <th>ZNF781</th>\n",
       "      <th>ZSCAN18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADAMTS20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577176</td>\n",
       "      <td>0.689548</td>\n",
       "      <td>0.811536</td>\n",
       "      <td>0.793435</td>\n",
       "      <td>0.796050</td>\n",
       "      <td>0.865384</td>\n",
       "      <td>0.288938</td>\n",
       "      <td>0.724191</td>\n",
       "      <td>0.763671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718813</td>\n",
       "      <td>0.469702</td>\n",
       "      <td>0.664124</td>\n",
       "      <td>0.746487</td>\n",
       "      <td>0.763971</td>\n",
       "      <td>0.691306</td>\n",
       "      <td>0.779107</td>\n",
       "      <td>0.797409</td>\n",
       "      <td>0.772388</td>\n",
       "      <td>0.774362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADCY4</th>\n",
       "      <td>0.577176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.572087</td>\n",
       "      <td>0.746949</td>\n",
       "      <td>0.773581</td>\n",
       "      <td>0.737435</td>\n",
       "      <td>0.691075</td>\n",
       "      <td>0.154626</td>\n",
       "      <td>0.677446</td>\n",
       "      <td>0.575162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577385</td>\n",
       "      <td>0.480065</td>\n",
       "      <td>0.640341</td>\n",
       "      <td>0.685082</td>\n",
       "      <td>0.616422</td>\n",
       "      <td>0.685534</td>\n",
       "      <td>0.723424</td>\n",
       "      <td>0.717358</td>\n",
       "      <td>0.700533</td>\n",
       "      <td>0.674430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIP</th>\n",
       "      <td>0.689548</td>\n",
       "      <td>0.572087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525277</td>\n",
       "      <td>0.684875</td>\n",
       "      <td>0.630310</td>\n",
       "      <td>0.736473</td>\n",
       "      <td>0.154056</td>\n",
       "      <td>0.662240</td>\n",
       "      <td>0.564364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700663</td>\n",
       "      <td>0.547216</td>\n",
       "      <td>0.638608</td>\n",
       "      <td>0.711940</td>\n",
       "      <td>0.608903</td>\n",
       "      <td>0.669713</td>\n",
       "      <td>0.522115</td>\n",
       "      <td>0.637378</td>\n",
       "      <td>0.303839</td>\n",
       "      <td>0.290034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALX1</th>\n",
       "      <td>0.811536</td>\n",
       "      <td>0.746949</td>\n",
       "      <td>0.525277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329106</td>\n",
       "      <td>0.734757</td>\n",
       "      <td>0.769313</td>\n",
       "      <td>0.159371</td>\n",
       "      <td>0.791724</td>\n",
       "      <td>0.632017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787421</td>\n",
       "      <td>0.604176</td>\n",
       "      <td>0.778586</td>\n",
       "      <td>0.793390</td>\n",
       "      <td>0.650497</td>\n",
       "      <td>0.651433</td>\n",
       "      <td>0.496802</td>\n",
       "      <td>0.400449</td>\n",
       "      <td>0.196909</td>\n",
       "      <td>0.151033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALX4</th>\n",
       "      <td>0.793435</td>\n",
       "      <td>0.773581</td>\n",
       "      <td>0.684875</td>\n",
       "      <td>0.329106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674850</td>\n",
       "      <td>0.810003</td>\n",
       "      <td>0.164211</td>\n",
       "      <td>0.801620</td>\n",
       "      <td>0.635208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744857</td>\n",
       "      <td>0.600006</td>\n",
       "      <td>0.799133</td>\n",
       "      <td>0.779394</td>\n",
       "      <td>0.650163</td>\n",
       "      <td>0.548934</td>\n",
       "      <td>0.548359</td>\n",
       "      <td>0.468631</td>\n",
       "      <td>0.132878</td>\n",
       "      <td>0.056669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ADAMTS20     ADCY4       AIP      ALX1      ALX4   ATG16L1  \\\n",
       "ADAMTS20  0.000000  0.577176  0.689548  0.811536  0.793435  0.796050   \n",
       "ADCY4     0.577176  0.000000  0.572087  0.746949  0.773581  0.737435   \n",
       "AIP       0.689548  0.572087  0.000000  0.525277  0.684875  0.630310   \n",
       "ALX1      0.811536  0.746949  0.525277  0.000000  0.329106  0.734757   \n",
       "ALX4      0.793435  0.773581  0.684875  0.329106  0.000000  0.674850   \n",
       "\n",
       "            ATP5G2  C1orf114       CA3     CCDC8  ...      TAC1   TMEM196  \\\n",
       "ADAMTS20  0.865384  0.288938  0.724191  0.763671  ...  0.718813  0.469702   \n",
       "ADCY4     0.691075  0.154626  0.677446  0.575162  ...  0.577385  0.480065   \n",
       "AIP       0.736473  0.154056  0.662240  0.564364  ...  0.700663  0.547216   \n",
       "ALX1      0.769313  0.159371  0.791724  0.632017  ...  0.787421  0.604176   \n",
       "ALX4      0.810003  0.164211  0.801620  0.635208  ...  0.744857  0.600006   \n",
       "\n",
       "            TRIM59     TUBB6      WDR8      WNT3   ZC3H12D     ZFP42  \\\n",
       "ADAMTS20  0.664124  0.746487  0.763971  0.691306  0.779107  0.797409   \n",
       "ADCY4     0.640341  0.685082  0.616422  0.685534  0.723424  0.717358   \n",
       "AIP       0.638608  0.711940  0.608903  0.669713  0.522115  0.637378   \n",
       "ALX1      0.778586  0.793390  0.650497  0.651433  0.496802  0.400449   \n",
       "ALX4      0.799133  0.779394  0.650163  0.548934  0.548359  0.468631   \n",
       "\n",
       "            ZNF781   ZSCAN18  \n",
       "ADAMTS20  0.772388  0.774362  \n",
       "ADCY4     0.700533  0.674430  \n",
       "AIP       0.303839  0.290034  \n",
       "ALX1      0.196909  0.151033  \n",
       "ALX4      0.132878  0.056669  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = [count for count in terms_count[\"count\"]]\n",
    "weight = weight / np.sum(weight)\n",
    "masks = np.array([~np.isnan(distance_matrix[i].values) for i in range(3)])\n",
    "\n",
    "valid_weights = np.array([weight[i] for i in range(3)])[:, None, None] * masks\n",
    "\n",
    "weight_sums = valid_weights.sum(axis=0)\n",
    "\n",
    "normalized_weights = np.divide(valid_weights, weight_sums, where=weight_sums != 0)\n",
    "weighted_sum = sum(\n",
    "    np.nan_to_num(distance_matrix[i].values) * normalized_weights[i] for i in range(3)\n",
    ")\n",
    "\n",
    "\n",
    "weighted_sum_dataframe = pd.DataFrame(weighted_sum, index=index, columns=index)\n",
    "\n",
    "weighted_sum_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of clusters: 4\n"
     ]
    }
   ],
   "source": [
    "cluster_result_weighted = hierarchical_clustering(\n",
    "    weighted_sum_dataframe,\n",
    "    range_min=3,\n",
    "    range_max=4,\n",
    "    out_path=f\"{result_out_path}/hierarchical_clustering_weighted_sum.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADAMTS20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADCY4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALX4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gene  cluster\n",
       "0  ADAMTS20        3\n",
       "1     ADCY4        3\n",
       "2       AIP        4\n",
       "3      ALX1        1\n",
       "4      ALX4        1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_result_weighted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Simple average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADAMTS20</th>\n",
       "      <th>ADCY4</th>\n",
       "      <th>AIP</th>\n",
       "      <th>ALX1</th>\n",
       "      <th>ALX4</th>\n",
       "      <th>ATG16L1</th>\n",
       "      <th>ATP5G2</th>\n",
       "      <th>C1orf114</th>\n",
       "      <th>CA3</th>\n",
       "      <th>CCDC8</th>\n",
       "      <th>...</th>\n",
       "      <th>TAC1</th>\n",
       "      <th>TMEM196</th>\n",
       "      <th>TRIM59</th>\n",
       "      <th>TUBB6</th>\n",
       "      <th>WDR8</th>\n",
       "      <th>WNT3</th>\n",
       "      <th>ZC3H12D</th>\n",
       "      <th>ZFP42</th>\n",
       "      <th>ZNF781</th>\n",
       "      <th>ZSCAN18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADAMTS20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600667</td>\n",
       "      <td>0.694667</td>\n",
       "      <td>0.799667</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.768667</td>\n",
       "      <td>0.851000</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>0.645667</td>\n",
       "      <td>0.719333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.663667</td>\n",
       "      <td>0.696000</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.752333</td>\n",
       "      <td>0.742667</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADCY4</th>\n",
       "      <td>0.600667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478333</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>0.703000</td>\n",
       "      <td>0.610333</td>\n",
       "      <td>0.659000</td>\n",
       "      <td>0.306000</td>\n",
       "      <td>0.527333</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549333</td>\n",
       "      <td>0.294667</td>\n",
       "      <td>0.597667</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>0.466333</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>0.625667</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>0.602667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIP</th>\n",
       "      <td>0.694667</td>\n",
       "      <td>0.478333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485667</td>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.532333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>0.336333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647667</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.587667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>0.487333</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>0.331667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALX1</th>\n",
       "      <td>0.799667</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>0.485667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220667</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.682667</td>\n",
       "      <td>0.322667</td>\n",
       "      <td>0.684667</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711667</td>\n",
       "      <td>0.468333</td>\n",
       "      <td>0.632333</td>\n",
       "      <td>0.637333</td>\n",
       "      <td>0.480333</td>\n",
       "      <td>0.590667</td>\n",
       "      <td>0.428667</td>\n",
       "      <td>0.368667</td>\n",
       "      <td>0.182667</td>\n",
       "      <td>0.114333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALX4</th>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.703000</td>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.220667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>0.717333</td>\n",
       "      <td>0.339667</td>\n",
       "      <td>0.709000</td>\n",
       "      <td>0.440333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691333</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.682333</td>\n",
       "      <td>0.642333</td>\n",
       "      <td>0.471333</td>\n",
       "      <td>0.540667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.074667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ADAMTS20     ADCY4       AIP      ALX1      ALX4   ATG16L1  \\\n",
       "ADAMTS20  0.000000  0.600667  0.694667  0.799667  0.792000  0.768667   \n",
       "ADCY4     0.600667  0.000000  0.478333  0.678333  0.703000  0.610333   \n",
       "AIP       0.694667  0.478333  0.000000  0.485667  0.581000  0.532333   \n",
       "ALX1      0.799667  0.678333  0.485667  0.000000  0.220667  0.635000   \n",
       "ALX4      0.792000  0.703000  0.581000  0.220667  0.000000  0.621667   \n",
       "\n",
       "            ATP5G2  C1orf114       CA3     CCDC8  ...      TAC1   TMEM196  \\\n",
       "ADAMTS20  0.851000  0.524000  0.645667  0.719333  ...  0.680000  0.407000   \n",
       "ADCY4     0.659000  0.306000  0.527333  0.386000  ...  0.549333  0.294667   \n",
       "AIP       0.666667  0.304000  0.528000  0.336333  ...  0.647667  0.372000   \n",
       "ALX1      0.682667  0.322667  0.684667  0.435000  ...  0.711667  0.468333   \n",
       "ALX4      0.717333  0.339667  0.709000  0.440333  ...  0.691333  0.485000   \n",
       "\n",
       "            TRIM59     TUBB6      WDR8      WNT3   ZC3H12D     ZFP42  \\\n",
       "ADAMTS20  0.663667  0.696000  0.738000  0.631667  0.746667  0.752333   \n",
       "ADCY4     0.597667  0.577000  0.466333  0.581667  0.625667  0.603000   \n",
       "AIP       0.587667  0.600000  0.451667  0.551000  0.487333  0.538000   \n",
       "ALX1      0.632333  0.637333  0.480333  0.590667  0.428667  0.368667   \n",
       "ALX4      0.682333  0.642333  0.471333  0.540667  0.466667  0.360000   \n",
       "\n",
       "            ZNF781   ZSCAN18  \n",
       "ADAMTS20  0.742667  0.750000  \n",
       "ADCY4     0.646000  0.602667  \n",
       "AIP       0.386667  0.331667  \n",
       "ALX1      0.182667  0.114333  \n",
       "ALX4      0.143000  0.074667  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = [1, 1, 1]\n",
    "masks = np.array([~np.isnan(distance_matrix[i].values) for i in range(3)])\n",
    "valid_weights = np.array([weight[i] for i in range(3)])[:, None, None] * masks\n",
    "weight_sums = valid_weights.sum(axis=0)\n",
    "normalized_weights = np.divide(valid_weights, weight_sums, where=weight_sums != 0)\n",
    "weighted_sum = sum(\n",
    "    np.nan_to_num(distance_matrix[i].values) * normalized_weights[i] for i in range(3)\n",
    ")\n",
    "simple_sum_dataframe = pd.DataFrame(weighted_sum, index=index, columns=index)\n",
    "simple_sum_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of clusters: 4\n"
     ]
    }
   ],
   "source": [
    "cluster_result_simple = hierarchical_clustering(\n",
    "    simple_sum_dataframe,\n",
    "    range_min=3,\n",
    "    range_max=4,\n",
    "    out_path=f\"{result_out_path}/hierarchical_clustering_simple_sum.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADAMTS20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADCY4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALX4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gene  cluster\n",
       "0  ADAMTS20        4\n",
       "1     ADCY4        4\n",
       "2       AIP        1\n",
       "3      ALX1        1\n",
       "4      ALX4        1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_result_simple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Consensus clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of clusters: 26\n",
      "Best number of clusters: 7\n",
      "Best number of clusters: 6\n"
     ]
    }
   ],
   "source": [
    "cluster_bp = hierarchical_clustering(\n",
    "    distance_matrix_bp, out_path=f\"{result_out_path}/hierarchical_clustering_bp.png\"\n",
    ")\n",
    "cluster_cc = hierarchical_clustering(\n",
    "    distance_matrix_cc, out_path=f\"{result_out_path}/hierarchical_clustering_cc.png\"\n",
    ")\n",
    "cluster_mf = hierarchical_clustering(\n",
    "    distance_matrix_mf, out_path=f\"{result_out_path}/hierarchical_clustering_mf.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>cluster_bp</th>\n",
       "      <th>cluster_cc</th>\n",
       "      <th>cluster_mf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADAMTS20</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADCY4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALX1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALX4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gene  cluster_bp  cluster_cc  cluster_mf\n",
       "0  ADAMTS20        11.0           3         6.0\n",
       "1     ADCY4        11.0           7         2.0\n",
       "2       AIP         1.0           7         2.0\n",
       "3      ALX1         1.0           1         1.0\n",
       "4      ALX4         2.0           1         1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_bp.columns = [\"gene\", \"cluster_bp\"]\n",
    "cluster_cc.columns = [\"gene\", \"cluster_cc\"]\n",
    "cluster_mf.columns = [\"gene\", \"cluster_mf\"]\n",
    "cluster_bp_cc = pd.merge(cluster_bp, cluster_cc, on=\"gene\", how=\"outer\")\n",
    "cluster_go = pd.merge(cluster_bp_cc, cluster_mf, on=\"gene\", how=\"outer\")\n",
    "cluster_go = cluster_go.fillna(-1)\n",
    "print(cluster_go.shape)\n",
    "cluster_go.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gene</th>\n",
       "      <th>ADAMTS20</th>\n",
       "      <th>ADCY4</th>\n",
       "      <th>AIP</th>\n",
       "      <th>ALX1</th>\n",
       "      <th>ALX4</th>\n",
       "      <th>ATG16L1</th>\n",
       "      <th>ATP5G2</th>\n",
       "      <th>C1orf114</th>\n",
       "      <th>CA3</th>\n",
       "      <th>CCDC8</th>\n",
       "      <th>...</th>\n",
       "      <th>TAC1</th>\n",
       "      <th>TMEM196</th>\n",
       "      <th>TRIM59</th>\n",
       "      <th>TUBB6</th>\n",
       "      <th>WDR8</th>\n",
       "      <th>WNT3</th>\n",
       "      <th>ZC3H12D</th>\n",
       "      <th>ZFP42</th>\n",
       "      <th>ZNF781</th>\n",
       "      <th>ZSCAN18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADAMTS20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADCY4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIP</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALX1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALX4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "gene      ADAMTS20     ADCY4       AIP      ALX1      ALX4   ATG16L1  \\\n",
       "gene                                                                   \n",
       "ADAMTS20  0.000000  0.666667  1.000000  1.000000  1.000000  1.000000   \n",
       "ADCY4     0.666667  0.000000  0.333333  1.000000  1.000000  0.333333   \n",
       "AIP       1.000000  0.333333  0.000000  0.666667  1.000000  0.333333   \n",
       "ALX1      1.000000  1.000000  0.666667  0.000000  0.333333  1.000000   \n",
       "ALX4      1.000000  1.000000  1.000000  0.333333  0.000000  1.000000   \n",
       "\n",
       "gene        ATP5G2  C1orf114       CA3     CCDC8  ...      TAC1   TMEM196  \\\n",
       "gene                                              ...                       \n",
       "ADAMTS20  1.000000  1.000000  1.000000  1.000000  ...  0.666667  1.000000   \n",
       "ADCY4     0.666667  0.333333  0.333333  0.333333  ...  0.666667  0.666667   \n",
       "AIP       0.666667  0.333333  0.333333  0.333333  ...  0.666667  0.666667   \n",
       "ALX1      1.000000  1.000000  1.000000  1.000000  ...  1.000000  1.000000   \n",
       "ALX4      1.000000  1.000000  1.000000  1.000000  ...  1.000000  1.000000   \n",
       "\n",
       "gene        TRIM59     TUBB6      WDR8      WNT3   ZC3H12D     ZFP42  \\\n",
       "gene                                                                   \n",
       "ADAMTS20  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "ADCY4     0.666667  0.333333  0.333333  0.666667  0.666667  1.000000   \n",
       "AIP       0.666667  0.333333  0.333333  0.666667  0.666667  0.666667   \n",
       "ALX1      1.000000  1.000000  1.000000  1.000000  0.666667  0.000000   \n",
       "ALX4      1.000000  1.000000  1.000000  1.000000  0.666667  0.333333   \n",
       "\n",
       "gene        ZNF781   ZSCAN18  \n",
       "gene                          \n",
       "ADAMTS20  0.666667  1.000000  \n",
       "ADCY4     1.000000  1.000000  \n",
       "AIP       0.666667  1.000000  \n",
       "ALX1      0.333333  0.333333  \n",
       "ALX4      0.666667  0.333333  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_genes = cluster_go.shape[0]\n",
    "consensus_matrix = np.zeros((num_genes, num_genes))\n",
    "for i in range(num_genes):\n",
    "    for j in range(i, num_genes):\n",
    "        if cluster_go.iloc[i][\"cluster_bp\"] == cluster_go.iloc[j][\"cluster_bp\"]:\n",
    "            consensus_matrix[i][j] += 1\n",
    "\n",
    "        if cluster_go.iloc[i][\"cluster_cc\"] == cluster_go.iloc[j][\"cluster_cc\"]:\n",
    "            consensus_matrix[i][j] += 1\n",
    "\n",
    "        if cluster_go.iloc[i][\"cluster_mf\"] == cluster_go.iloc[j][\"cluster_mf\"]:\n",
    "            consensus_matrix[i][j] += 1\n",
    "\n",
    "consensus_matrix = pd.DataFrame(\n",
    "    consensus_matrix, index=cluster_go[\"gene\"], columns=cluster_go[\"gene\"]\n",
    ")\n",
    "consensus_matrix += consensus_matrix.T\n",
    "distance_matrix_consensus = 1 - consensus_matrix / 3\n",
    "np.fill_diagonal(distance_matrix_consensus.values, 0)\n",
    "distance_matrix_consensus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of clusters: 4\n"
     ]
    }
   ],
   "source": [
    "cluster_result_consensus = hierarchical_clustering(\n",
    "    distance_matrix_consensus,\n",
    "    range_min=3,\n",
    "    range_max=4,\n",
    "    out_path=f\"{result_out_path}/hierarchical_clustering_consensus.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADAMTS20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADCY4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALX4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gene  cluster\n",
       "0  ADAMTS20        2\n",
       "1     ADCY4        2\n",
       "2       AIP        2\n",
       "3      ALX1        1\n",
       "4      ALX4        1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_result_consensus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of clusters for Weighted Average: 4\n",
      "Best number of clusters for Simple Average: 4\n",
      "Best number of clusters for Consensus: 4\n"
     ]
    }
   ],
   "source": [
    "from utils.clustering_helper import hierarchical_clustering_compare\n",
    "\n",
    "hierarchical_clustering_compare(\n",
    "    [weighted_sum_dataframe, simple_sum_dataframe, distance_matrix_consensus],\n",
    "    [\"Weighted Average\", \"Simple Average\", \"Consensus\"],\n",
    "    out_path=f\"{result_out_path}/hierarchical_clustering_compare.png\",\n",
    "    range_min=3,\n",
    "    range_max=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_info = pd.read_csv(dbeta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column gene isin weighted_sum_dataframe\n",
    "weighted_dbeta = dbeta_info[dbeta_info[\"gene\"].isin(weighted_sum_dataframe.index)]\n",
    "simple_dbeta = dbeta_info[dbeta_info[\"gene\"].isin(simple_sum_dataframe.index)]\n",
    "consensus_dbeta = dbeta_info[dbeta_info[\"gene\"].isin(distance_matrix_consensus.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_dbeta.merge(cluster_result_weighted, on=\"gene\").to_csv(\n",
    "    f\"{result_out_path}/{result_prefix}_weighted.csv\", index=False\n",
    ")\n",
    "simple_dbeta.merge(cluster_result_simple, on=\"gene\").to_csv(\n",
    "    f\"{result_out_path}/{result_prefix}_simple.csv\", index=False\n",
    ")\n",
    "consensus_dbeta.merge(cluster_result_consensus, on=\"gene\").to_csv(\n",
    "    f\"{result_out_path}/{result_prefix}_consensus.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec. 6 SimpleModel Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_helper import read_selected_features_json\n",
    "import pandas as pd\n",
    "from utils.process_norm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta_file = config[\"simple_model\"][\"hyper\"][\"dbeta_file\"]\n",
    "selected_feature_file = config[\"simple_model\"][\"hyper\"][\"selected_feature_file\"]\n",
    "selected_feature_file_2 = config[\"simple_model\"][\"hyper\"][\"selected_feature_file_2\"]\n",
    "train_out_path = config[\"simple_model\"][\"hyper\"][\"train_out_path\"]\n",
    "validate_out_path = config[\"simple_model\"][\"hyper\"][\"validate_out_path\"]\n",
    "df_train_file = config[\"simple_model\"][\"hyper\"][\"df_train_file\"]\n",
    "df_test_file = config[\"simple_model\"][\"hyper\"][\"df_test_file\"]\n",
    "df_train_file_2 = config[\"simple_model\"][\"hyper\"][\"df_train_file_2\"]\n",
    "df_test_file_2 = config[\"simple_model\"][\"hyper\"][\"df_test_file_2\"]\n",
    "training_param_file = config[\"simple_model\"][\"hyper\"][\"training_param_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature = read_selected_features_json(selected_feature_file)\n",
    "selected_feature_2 = read_selected_features_json(selected_feature_file_2)\n",
    "dbeta_file = pd.read_csv(dbeta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(df_train_file)\n",
    "test = pd.read_csv(df_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO Columns with NaNs: {'265': np.float64(1.0)}\n"
     ]
    }
   ],
   "source": [
    "train = inspect_nan(train, mode=\"column\", remove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2 = pd.read_csv(df_train_file_2)\n",
    "test_2 = pd.read_csv(df_test_file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>826</th>\n",
       "      <th>827</th>\n",
       "      <th>828</th>\n",
       "      <th>829</th>\n",
       "      <th>830</th>\n",
       "      <th>831</th>\n",
       "      <th>832</th>\n",
       "      <th>833</th>\n",
       "      <th>834</th>\n",
       "      <th>835</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cg00000957</td>\n",
       "      <td>0.870131</td>\n",
       "      <td>0.866782</td>\n",
       "      <td>0.841300</td>\n",
       "      <td>0.867264</td>\n",
       "      <td>0.870941</td>\n",
       "      <td>0.835596</td>\n",
       "      <td>0.882055</td>\n",
       "      <td>0.847299</td>\n",
       "      <td>0.867437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669044</td>\n",
       "      <td>0.870513</td>\n",
       "      <td>0.878363</td>\n",
       "      <td>0.867401</td>\n",
       "      <td>0.872652</td>\n",
       "      <td>0.893914</td>\n",
       "      <td>0.881826</td>\n",
       "      <td>0.861232</td>\n",
       "      <td>0.863374</td>\n",
       "      <td>0.864288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cg00001583</td>\n",
       "      <td>0.130379</td>\n",
       "      <td>0.070445</td>\n",
       "      <td>0.139665</td>\n",
       "      <td>0.146764</td>\n",
       "      <td>0.071685</td>\n",
       "      <td>0.126561</td>\n",
       "      <td>0.123222</td>\n",
       "      <td>0.127817</td>\n",
       "      <td>0.102428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044154</td>\n",
       "      <td>0.479830</td>\n",
       "      <td>0.324485</td>\n",
       "      <td>0.064659</td>\n",
       "      <td>0.625846</td>\n",
       "      <td>0.716061</td>\n",
       "      <td>0.646429</td>\n",
       "      <td>0.143131</td>\n",
       "      <td>0.651526</td>\n",
       "      <td>0.436335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cg00002028</td>\n",
       "      <td>0.027859</td>\n",
       "      <td>0.034231</td>\n",
       "      <td>0.037926</td>\n",
       "      <td>0.026836</td>\n",
       "      <td>0.025741</td>\n",
       "      <td>0.016993</td>\n",
       "      <td>0.085896</td>\n",
       "      <td>0.033704</td>\n",
       "      <td>0.028174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093667</td>\n",
       "      <td>0.060649</td>\n",
       "      <td>0.059475</td>\n",
       "      <td>0.058768</td>\n",
       "      <td>0.028895</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>0.049330</td>\n",
       "      <td>0.020692</td>\n",
       "      <td>0.053677</td>\n",
       "      <td>0.048020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cg00002719</td>\n",
       "      <td>0.024905</td>\n",
       "      <td>0.049881</td>\n",
       "      <td>0.062630</td>\n",
       "      <td>0.027035</td>\n",
       "      <td>0.023960</td>\n",
       "      <td>0.037078</td>\n",
       "      <td>0.063606</td>\n",
       "      <td>0.044801</td>\n",
       "      <td>0.026103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143065</td>\n",
       "      <td>0.240834</td>\n",
       "      <td>0.220422</td>\n",
       "      <td>0.032740</td>\n",
       "      <td>0.238104</td>\n",
       "      <td>0.674085</td>\n",
       "      <td>0.644529</td>\n",
       "      <td>0.098214</td>\n",
       "      <td>0.760026</td>\n",
       "      <td>0.395033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cg00002837</td>\n",
       "      <td>0.317879</td>\n",
       "      <td>0.276213</td>\n",
       "      <td>0.293055</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.251165</td>\n",
       "      <td>0.384913</td>\n",
       "      <td>0.300542</td>\n",
       "      <td>0.275221</td>\n",
       "      <td>0.380311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400248</td>\n",
       "      <td>0.492348</td>\n",
       "      <td>0.294186</td>\n",
       "      <td>0.500739</td>\n",
       "      <td>0.414480</td>\n",
       "      <td>0.451829</td>\n",
       "      <td>0.721043</td>\n",
       "      <td>0.266971</td>\n",
       "      <td>0.179254</td>\n",
       "      <td>0.562186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294377</th>\n",
       "      <td>cg27657363</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>0.966018</td>\n",
       "      <td>0.949426</td>\n",
       "      <td>0.906193</td>\n",
       "      <td>0.957120</td>\n",
       "      <td>0.938661</td>\n",
       "      <td>0.946524</td>\n",
       "      <td>0.928793</td>\n",
       "      <td>0.955680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746055</td>\n",
       "      <td>0.925792</td>\n",
       "      <td>0.939424</td>\n",
       "      <td>0.897395</td>\n",
       "      <td>0.903703</td>\n",
       "      <td>0.958058</td>\n",
       "      <td>0.944749</td>\n",
       "      <td>0.942778</td>\n",
       "      <td>0.941170</td>\n",
       "      <td>0.899832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294378</th>\n",
       "      <td>cg27657537</td>\n",
       "      <td>0.060546</td>\n",
       "      <td>0.093363</td>\n",
       "      <td>0.158475</td>\n",
       "      <td>0.056264</td>\n",
       "      <td>0.060162</td>\n",
       "      <td>0.088070</td>\n",
       "      <td>0.160369</td>\n",
       "      <td>0.080986</td>\n",
       "      <td>0.097606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098622</td>\n",
       "      <td>0.148348</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>0.183956</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.075223</td>\n",
       "      <td>0.076596</td>\n",
       "      <td>0.059452</td>\n",
       "      <td>0.077612</td>\n",
       "      <td>0.095113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294379</th>\n",
       "      <td>cg27662611</td>\n",
       "      <td>0.034528</td>\n",
       "      <td>0.047549</td>\n",
       "      <td>0.058815</td>\n",
       "      <td>0.044475</td>\n",
       "      <td>0.029043</td>\n",
       "      <td>0.037124</td>\n",
       "      <td>0.068912</td>\n",
       "      <td>0.054865</td>\n",
       "      <td>0.037603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027905</td>\n",
       "      <td>0.061222</td>\n",
       "      <td>0.045846</td>\n",
       "      <td>0.050612</td>\n",
       "      <td>0.076919</td>\n",
       "      <td>0.074944</td>\n",
       "      <td>0.065488</td>\n",
       "      <td>0.036783</td>\n",
       "      <td>0.069584</td>\n",
       "      <td>0.055491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294380</th>\n",
       "      <td>cg27665648</td>\n",
       "      <td>0.859977</td>\n",
       "      <td>0.905516</td>\n",
       "      <td>0.764569</td>\n",
       "      <td>0.818406</td>\n",
       "      <td>0.854048</td>\n",
       "      <td>0.672517</td>\n",
       "      <td>0.738127</td>\n",
       "      <td>0.798509</td>\n",
       "      <td>0.846691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879646</td>\n",
       "      <td>0.764174</td>\n",
       "      <td>0.847019</td>\n",
       "      <td>0.794012</td>\n",
       "      <td>0.674822</td>\n",
       "      <td>0.908401</td>\n",
       "      <td>0.890954</td>\n",
       "      <td>0.846817</td>\n",
       "      <td>0.890767</td>\n",
       "      <td>0.811262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294381</th>\n",
       "      <td>label</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294382 rows Ã— 837 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0         0         1         2         3         4  \\\n",
       "0       cg00000957  0.870131  0.866782  0.841300  0.867264  0.870941   \n",
       "1       cg00001583  0.130379  0.070445  0.139665  0.146764  0.071685   \n",
       "2       cg00002028  0.027859  0.034231  0.037926  0.026836  0.025741   \n",
       "3       cg00002719  0.024905  0.049881  0.062630  0.027035  0.023960   \n",
       "4       cg00002837  0.317879  0.276213  0.293055  0.242700  0.251165   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "294377  cg27657363  0.950697  0.966018  0.949426  0.906193  0.957120   \n",
       "294378  cg27657537  0.060546  0.093363  0.158475  0.056264  0.060162   \n",
       "294379  cg27662611  0.034528  0.047549  0.058815  0.044475  0.029043   \n",
       "294380  cg27665648  0.859977  0.905516  0.764569  0.818406  0.854048   \n",
       "294381       label  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "               5         6         7         8  ...       826       827  \\\n",
       "0       0.835596  0.882055  0.847299  0.867437  ...  0.669044  0.870513   \n",
       "1       0.126561  0.123222  0.127817  0.102428  ...  0.044154  0.479830   \n",
       "2       0.016993  0.085896  0.033704  0.028174  ...  0.093667  0.060649   \n",
       "3       0.037078  0.063606  0.044801  0.026103  ...  0.143065  0.240834   \n",
       "4       0.384913  0.300542  0.275221  0.380311  ...  0.400248  0.492348   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "294377  0.938661  0.946524  0.928793  0.955680  ...  0.746055  0.925792   \n",
       "294378  0.088070  0.160369  0.080986  0.097606  ...  0.098622  0.148348   \n",
       "294379  0.037124  0.068912  0.054865  0.037603  ...  0.027905  0.061222   \n",
       "294380  0.672517  0.738127  0.798509  0.846691  ...  0.879646  0.764174   \n",
       "294381  0.000000  0.000000  0.000000  0.000000  ...  1.000000  1.000000   \n",
       "\n",
       "             828       829       830       831       832       833       834  \\\n",
       "0       0.878363  0.867401  0.872652  0.893914  0.881826  0.861232  0.863374   \n",
       "1       0.324485  0.064659  0.625846  0.716061  0.646429  0.143131  0.651526   \n",
       "2       0.059475  0.058768  0.028895  0.042236  0.049330  0.020692  0.053677   \n",
       "3       0.220422  0.032740  0.238104  0.674085  0.644529  0.098214  0.760026   \n",
       "4       0.294186  0.500739  0.414480  0.451829  0.721043  0.266971  0.179254   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "294377  0.939424  0.897395  0.903703  0.958058  0.944749  0.942778  0.941170   \n",
       "294378  0.166300  0.183956  0.136002  0.075223  0.076596  0.059452  0.077612   \n",
       "294379  0.045846  0.050612  0.076919  0.074944  0.065488  0.036783  0.069584   \n",
       "294380  0.847019  0.794012  0.674822  0.908401  0.890954  0.846817  0.890767   \n",
       "294381  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "\n",
       "             835  \n",
       "0       0.864288  \n",
       "1       0.436335  \n",
       "2       0.048020  \n",
       "3       0.395033  \n",
       "4       0.562186  \n",
       "...          ...  \n",
       "294377  0.899832  \n",
       "294378  0.095113  \n",
       "294379  0.055491  \n",
       "294380  0.811262  \n",
       "294381  1.000000  \n",
       "\n",
       "[294382 rows x 837 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = merge_datasets(train, train_2)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cg00000957</td>\n",
       "      <td>0.880918</td>\n",
       "      <td>0.889138</td>\n",
       "      <td>0.874959</td>\n",
       "      <td>0.885774</td>\n",
       "      <td>0.896747</td>\n",
       "      <td>0.879334</td>\n",
       "      <td>0.858834</td>\n",
       "      <td>0.837964</td>\n",
       "      <td>0.876630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824397</td>\n",
       "      <td>0.897076</td>\n",
       "      <td>0.884351</td>\n",
       "      <td>0.891127</td>\n",
       "      <td>0.937575</td>\n",
       "      <td>0.778774</td>\n",
       "      <td>0.867760</td>\n",
       "      <td>0.874922</td>\n",
       "      <td>0.839929</td>\n",
       "      <td>0.889266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cg00001583</td>\n",
       "      <td>0.066911</td>\n",
       "      <td>0.076375</td>\n",
       "      <td>0.096527</td>\n",
       "      <td>0.040940</td>\n",
       "      <td>0.083554</td>\n",
       "      <td>0.087588</td>\n",
       "      <td>0.061910</td>\n",
       "      <td>0.069474</td>\n",
       "      <td>0.093006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576252</td>\n",
       "      <td>0.053651</td>\n",
       "      <td>0.576651</td>\n",
       "      <td>0.146280</td>\n",
       "      <td>0.380901</td>\n",
       "      <td>0.073419</td>\n",
       "      <td>0.165535</td>\n",
       "      <td>0.066819</td>\n",
       "      <td>0.094443</td>\n",
       "      <td>0.132342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cg00002028</td>\n",
       "      <td>0.023719</td>\n",
       "      <td>0.037065</td>\n",
       "      <td>0.021660</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.027399</td>\n",
       "      <td>0.024558</td>\n",
       "      <td>0.035275</td>\n",
       "      <td>0.017022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137957</td>\n",
       "      <td>0.097596</td>\n",
       "      <td>0.101154</td>\n",
       "      <td>0.114899</td>\n",
       "      <td>0.162179</td>\n",
       "      <td>0.096768</td>\n",
       "      <td>0.092990</td>\n",
       "      <td>0.058361</td>\n",
       "      <td>0.124010</td>\n",
       "      <td>0.119324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cg00002719</td>\n",
       "      <td>0.018851</td>\n",
       "      <td>0.024845</td>\n",
       "      <td>0.023367</td>\n",
       "      <td>0.012765</td>\n",
       "      <td>0.010090</td>\n",
       "      <td>0.017774</td>\n",
       "      <td>0.046654</td>\n",
       "      <td>0.026357</td>\n",
       "      <td>0.026142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801550</td>\n",
       "      <td>0.147161</td>\n",
       "      <td>0.645241</td>\n",
       "      <td>0.285699</td>\n",
       "      <td>0.941672</td>\n",
       "      <td>0.161863</td>\n",
       "      <td>0.075074</td>\n",
       "      <td>0.279016</td>\n",
       "      <td>0.330795</td>\n",
       "      <td>0.039894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cg00002837</td>\n",
       "      <td>0.231168</td>\n",
       "      <td>0.263481</td>\n",
       "      <td>0.326748</td>\n",
       "      <td>0.212321</td>\n",
       "      <td>0.233503</td>\n",
       "      <td>0.228290</td>\n",
       "      <td>0.271203</td>\n",
       "      <td>0.376430</td>\n",
       "      <td>0.252944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243319</td>\n",
       "      <td>0.499297</td>\n",
       "      <td>0.359858</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>0.340304</td>\n",
       "      <td>0.419111</td>\n",
       "      <td>0.396845</td>\n",
       "      <td>0.550041</td>\n",
       "      <td>0.452268</td>\n",
       "      <td>0.356127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294377</th>\n",
       "      <td>cg27657363</td>\n",
       "      <td>0.965252</td>\n",
       "      <td>0.881412</td>\n",
       "      <td>0.961724</td>\n",
       "      <td>0.957276</td>\n",
       "      <td>0.956891</td>\n",
       "      <td>0.954883</td>\n",
       "      <td>0.953429</td>\n",
       "      <td>0.948396</td>\n",
       "      <td>0.957826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856380</td>\n",
       "      <td>0.791323</td>\n",
       "      <td>0.927085</td>\n",
       "      <td>0.842508</td>\n",
       "      <td>0.755541</td>\n",
       "      <td>0.882560</td>\n",
       "      <td>0.884853</td>\n",
       "      <td>0.734444</td>\n",
       "      <td>0.651562</td>\n",
       "      <td>0.877115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294378</th>\n",
       "      <td>cg27657537</td>\n",
       "      <td>0.049765</td>\n",
       "      <td>0.117931</td>\n",
       "      <td>0.061232</td>\n",
       "      <td>0.034888</td>\n",
       "      <td>0.055366</td>\n",
       "      <td>0.067702</td>\n",
       "      <td>0.054141</td>\n",
       "      <td>0.083854</td>\n",
       "      <td>0.062192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038267</td>\n",
       "      <td>0.039257</td>\n",
       "      <td>0.054078</td>\n",
       "      <td>0.060248</td>\n",
       "      <td>0.065395</td>\n",
       "      <td>0.052062</td>\n",
       "      <td>0.068284</td>\n",
       "      <td>0.049476</td>\n",
       "      <td>0.031694</td>\n",
       "      <td>0.089036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294379</th>\n",
       "      <td>cg27662611</td>\n",
       "      <td>0.042660</td>\n",
       "      <td>0.063932</td>\n",
       "      <td>0.055080</td>\n",
       "      <td>0.034882</td>\n",
       "      <td>0.017662</td>\n",
       "      <td>0.042007</td>\n",
       "      <td>0.042645</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.047642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025175</td>\n",
       "      <td>0.025053</td>\n",
       "      <td>0.013499</td>\n",
       "      <td>0.017525</td>\n",
       "      <td>0.135137</td>\n",
       "      <td>0.031272</td>\n",
       "      <td>0.009832</td>\n",
       "      <td>0.023495</td>\n",
       "      <td>0.026024</td>\n",
       "      <td>0.017780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294380</th>\n",
       "      <td>cg27665648</td>\n",
       "      <td>0.872041</td>\n",
       "      <td>0.797600</td>\n",
       "      <td>0.829041</td>\n",
       "      <td>0.863131</td>\n",
       "      <td>0.896679</td>\n",
       "      <td>0.838608</td>\n",
       "      <td>0.709252</td>\n",
       "      <td>0.742108</td>\n",
       "      <td>0.832386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793646</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>0.932568</td>\n",
       "      <td>0.792866</td>\n",
       "      <td>0.962920</td>\n",
       "      <td>0.757222</td>\n",
       "      <td>0.865069</td>\n",
       "      <td>0.638925</td>\n",
       "      <td>0.638460</td>\n",
       "      <td>0.927500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294381</th>\n",
       "      <td>label</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294382 rows Ã— 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0         0         1         2         3         4  \\\n",
       "0       cg00000957  0.880918  0.889138  0.874959  0.885774  0.896747   \n",
       "1       cg00001583  0.066911  0.076375  0.096527  0.040940  0.083554   \n",
       "2       cg00002028  0.023719  0.037065  0.021660  0.010759  0.010474   \n",
       "3       cg00002719  0.018851  0.024845  0.023367  0.012765  0.010090   \n",
       "4       cg00002837  0.231168  0.263481  0.326748  0.212321  0.233503   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "294377  cg27657363  0.965252  0.881412  0.961724  0.957276  0.956891   \n",
       "294378  cg27657537  0.049765  0.117931  0.061232  0.034888  0.055366   \n",
       "294379  cg27662611  0.042660  0.063932  0.055080  0.034882  0.017662   \n",
       "294380  cg27665648  0.872041  0.797600  0.829041  0.863131  0.896679   \n",
       "294381       label  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "               5         6         7         8  ...       200       201  \\\n",
       "0       0.879334  0.858834  0.837964  0.876630  ...  0.824397  0.897076   \n",
       "1       0.087588  0.061910  0.069474  0.093006  ...  0.576252  0.053651   \n",
       "2       0.027399  0.024558  0.035275  0.017022  ...  0.137957  0.097596   \n",
       "3       0.017774  0.046654  0.026357  0.026142  ...  0.801550  0.147161   \n",
       "4       0.228290  0.271203  0.376430  0.252944  ...  0.243319  0.499297   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "294377  0.954883  0.953429  0.948396  0.957826  ...  0.856380  0.791323   \n",
       "294378  0.067702  0.054141  0.083854  0.062192  ...  0.038267  0.039257   \n",
       "294379  0.042007  0.042645  0.047950  0.047642  ...  0.025175  0.025053   \n",
       "294380  0.838608  0.709252  0.742108  0.832386  ...  0.793646  0.676673   \n",
       "294381  0.000000  0.000000  0.000000  0.000000  ...  1.000000  1.000000   \n",
       "\n",
       "             202       203       204       205       206       207       208  \\\n",
       "0       0.884351  0.891127  0.937575  0.778774  0.867760  0.874922  0.839929   \n",
       "1       0.576651  0.146280  0.380901  0.073419  0.165535  0.066819  0.094443   \n",
       "2       0.101154  0.114899  0.162179  0.096768  0.092990  0.058361  0.124010   \n",
       "3       0.645241  0.285699  0.941672  0.161863  0.075074  0.279016  0.330795   \n",
       "4       0.359858  0.280982  0.340304  0.419111  0.396845  0.550041  0.452268   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "294377  0.927085  0.842508  0.755541  0.882560  0.884853  0.734444  0.651562   \n",
       "294378  0.054078  0.060248  0.065395  0.052062  0.068284  0.049476  0.031694   \n",
       "294379  0.013499  0.017525  0.135137  0.031272  0.009832  0.023495  0.026024   \n",
       "294380  0.932568  0.792866  0.962920  0.757222  0.865069  0.638925  0.638460   \n",
       "294381  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "\n",
       "             209  \n",
       "0       0.889266  \n",
       "1       0.132342  \n",
       "2       0.119324  \n",
       "3       0.039894  \n",
       "4       0.356127  \n",
       "...          ...  \n",
       "294377  0.877115  \n",
       "294378  0.089036  \n",
       "294379  0.017780  \n",
       "294380  0.927500  \n",
       "294381  1.000000  \n",
       "\n",
       "[294382 rows x 211 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = merge_datasets(test, test_2)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_helper import set_parameters\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import json\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "with open(training_param_file, \"r\") as f:\n",
    "    training_param = json.load(f)\n",
    "\n",
    "xgb_grid = set_parameters(XGBClassifier(random_state=42), training_param[\"XGBoost\"])\n",
    "rf_grid = set_parameters(RandomForestClassifier(random_state=42), training_param[\"RandomForest\"])\n",
    "svm_grid = set_parameters(SVC(random_state=42, probability=True), training_param[\"SVM\"])\n",
    "dt_grid = set_parameters(DecisionTreeClassifier(random_state=42), training_param[\"DecisionTree\"])\n",
    "lr_grid = set_parameters(LogisticRegression(random_state=42), training_param[\"LogisticRegression\"])\n",
    "lr_elastic_grid = set_parameters(LogisticRegression(random_state=42), training_param[\"LogisticRegressionElastic\"])\n",
    "voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"XGBoost\", XGBClassifier(random_state=42, n_estimators=50)), \n",
    "        (\"RandomForest\", RandomForestClassifier(random_state=42, n_estimators=50)),\n",
    "        (\"SVM\", SVC(random_state=42, probability=True)),\n",
    "        (\"DecisionTree\", DecisionTreeClassifier(random_state=42, max_depth=5)),\n",
    "        (\"LogisticRegression\", LogisticRegression(random_state=42, C=0.1)),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "\n",
    "# comment out the model you don't want to use\n",
    "models = {\n",
    "    \"XGBoost\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": xgb_grid,\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": rf_grid,\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": svm_grid,\n",
    "    },\n",
    "    \"DecisionTree\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": dt_grid,\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": lr_grid,\n",
    "    },\n",
    "    \"LogisticRegressionElastic\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": lr_elastic_grid,\n",
    "    },\n",
    "    \"Voting\": {\n",
    "        \"is_grid_search\": False,\n",
    "        \"model\": voting,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO Training for combination: ('FOXD2', 'GFRA2', 'MIR196A2', 'SCT') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('FOXD2', 'GHSR', 'MIR196A2', 'SCT') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('FOXD2', 'GFRA2', 'MIR196A2', 'SCT') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('FOXD2', 'GHSR', 'MIR196A2', 'SCT') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('FOXD2', 'GFRA2', 'MIR196A2', 'SCT') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXD2', 'GHSR', 'MIR196A2', 'SCT') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXD2', 'GFRA2', 'MIR196A2', 'SCT') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('FOXD2', 'GHSR', 'MIR196A2', 'SCT') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('FOXD2', 'GFRA2', 'MIR196A2', 'SCT') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXD2', 'GHSR', 'MIR196A2', 'SCT') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXD2', 'GFRA2', 'MIR196A2', 'SCT') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('FOXD2', 'GHSR', 'MIR196A2', 'SCT') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('FOXD2', 'GFRA2', 'MIR196A2', 'SCT') with estimator: Voting\n",
      "INFO Training for combination: ('FOXD2', 'GHSR', 'MIR196A2', 'SCT') with estimator: Voting\n",
      "INFO Training for combination: ('ALX1', 'GHITM', 'MIR654', 'PRLHR') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('ALX1', 'KRTAP20-1', 'MIR654', 'PRLHR') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('ALX1', 'NEFM', 'MIR654', 'PRLHR') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('ALX1', 'GHITM', 'MIR654', 'PRLHR') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('ALX1', 'KRTAP20-1', 'MIR654', 'PRLHR') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('ALX1', 'NEFM', 'MIR654', 'PRLHR') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('ALX1', 'GHITM', 'MIR654', 'PRLHR') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'KRTAP20-1', 'MIR654', 'PRLHR') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'NEFM', 'MIR654', 'PRLHR') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'GHITM', 'MIR654', 'PRLHR') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('ALX1', 'KRTAP20-1', 'MIR654', 'PRLHR') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('ALX1', 'NEFM', 'MIR654', 'PRLHR') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('ALX1', 'GHITM', 'MIR654', 'PRLHR') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'KRTAP20-1', 'MIR654', 'PRLHR') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'NEFM', 'MIR654', 'PRLHR') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'GHITM', 'MIR654', 'PRLHR') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('ALX1', 'KRTAP20-1', 'MIR654', 'PRLHR') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('ALX1', 'NEFM', 'MIR654', 'PRLHR') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('ALX1', 'GHITM', 'MIR654', 'PRLHR') with estimator: Voting\n",
      "INFO Training for combination: ('ALX1', 'KRTAP20-1', 'MIR654', 'PRLHR') with estimator: Voting\n",
      "INFO Training for combination: ('ALX1', 'NEFM', 'MIR654', 'PRLHR') with estimator: Voting\n",
      "INFO Training for combination: ('ALX1', 'ATP5G2', 'GFRA2', 'MIR196A2') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('ALX1', 'TAC1', 'GFRA2', 'MIR196A2') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('FOXD2', 'ATP5G2', 'GFRA2', 'MIR196A2') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('FOXD2', 'TAC1', 'GFRA2', 'MIR196A2') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('ALX1', 'ATP5G2', 'GFRA2', 'MIR196A2') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('ALX1', 'TAC1', 'GFRA2', 'MIR196A2') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('FOXD2', 'ATP5G2', 'GFRA2', 'MIR196A2') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('FOXD2', 'TAC1', 'GFRA2', 'MIR196A2') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('ALX1', 'ATP5G2', 'GFRA2', 'MIR196A2') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'TAC1', 'GFRA2', 'MIR196A2') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXD2', 'ATP5G2', 'GFRA2', 'MIR196A2') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXD2', 'TAC1', 'GFRA2', 'MIR196A2') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'ATP5G2', 'GFRA2', 'MIR196A2') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('ALX1', 'TAC1', 'GFRA2', 'MIR196A2') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('FOXD2', 'ATP5G2', 'GFRA2', 'MIR196A2') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('FOXD2', 'TAC1', 'GFRA2', 'MIR196A2') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('ALX1', 'ATP5G2', 'GFRA2', 'MIR196A2') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'TAC1', 'GFRA2', 'MIR196A2') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXD2', 'ATP5G2', 'GFRA2', 'MIR196A2') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXD2', 'TAC1', 'GFRA2', 'MIR196A2') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'ATP5G2', 'GFRA2', 'MIR196A2') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('ALX1', 'TAC1', 'GFRA2', 'MIR196A2') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('FOXD2', 'ATP5G2', 'GFRA2', 'MIR196A2') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('FOXD2', 'TAC1', 'GFRA2', 'MIR196A2') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('ALX1', 'ATP5G2', 'GFRA2', 'MIR196A2') with estimator: Voting\n",
      "INFO Training for combination: ('ALX1', 'TAC1', 'GFRA2', 'MIR196A2') with estimator: Voting\n",
      "INFO Training for combination: ('FOXD2', 'ATP5G2', 'GFRA2', 'MIR196A2') with estimator: Voting\n",
      "INFO Training for combination: ('FOXD2', 'TAC1', 'GFRA2', 'MIR196A2') with estimator: Voting\n",
      "INFO Training for combination: ('ALX1', 'CA3', 'GFRA2', 'MIR1197') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('ALX1', 'FRZB', 'GFRA2', 'MIR1197') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('FOXD2', 'CA3', 'GFRA2', 'MIR1197') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('FOXD2', 'FRZB', 'GFRA2', 'MIR1197') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('ALX1', 'CA3', 'GFRA2', 'MIR1197') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('ALX1', 'FRZB', 'GFRA2', 'MIR1197') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('FOXD2', 'CA3', 'GFRA2', 'MIR1197') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('FOXD2', 'FRZB', 'GFRA2', 'MIR1197') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('ALX1', 'CA3', 'GFRA2', 'MIR1197') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'FRZB', 'GFRA2', 'MIR1197') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXD2', 'CA3', 'GFRA2', 'MIR1197') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXD2', 'FRZB', 'GFRA2', 'MIR1197') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'CA3', 'GFRA2', 'MIR1197') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('ALX1', 'FRZB', 'GFRA2', 'MIR1197') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('FOXD2', 'CA3', 'GFRA2', 'MIR1197') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('FOXD2', 'FRZB', 'GFRA2', 'MIR1197') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('ALX1', 'CA3', 'GFRA2', 'MIR1197') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'FRZB', 'GFRA2', 'MIR1197') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXD2', 'CA3', 'GFRA2', 'MIR1197') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXD2', 'FRZB', 'GFRA2', 'MIR1197') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'CA3', 'GFRA2', 'MIR1197') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('ALX1', 'FRZB', 'GFRA2', 'MIR1197') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('FOXD2', 'CA3', 'GFRA2', 'MIR1197') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('FOXD2', 'FRZB', 'GFRA2', 'MIR1197') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('ALX1', 'CA3', 'GFRA2', 'MIR1197') with estimator: Voting\n",
      "INFO Training for combination: ('ALX1', 'FRZB', 'GFRA2', 'MIR1197') with estimator: Voting\n",
      "INFO Training for combination: ('FOXD2', 'CA3', 'GFRA2', 'MIR1197') with estimator: Voting\n",
      "INFO Training for combination: ('FOXD2', 'FRZB', 'GFRA2', 'MIR1197') with estimator: Voting\n",
      "INFO Training for combination: ('ALX1', 'CCDC8', 'GFRA2', 'MIR654') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('FOXD2', 'CCDC8', 'GFRA2', 'MIR654') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('POU3F3', 'CCDC8', 'GFRA2', 'MIR654') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('ALX1', 'CCDC8', 'GFRA2', 'MIR654') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('FOXD2', 'CCDC8', 'GFRA2', 'MIR654') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('POU3F3', 'CCDC8', 'GFRA2', 'MIR654') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('ALX1', 'CCDC8', 'GFRA2', 'MIR654') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXD2', 'CCDC8', 'GFRA2', 'MIR654') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('POU3F3', 'CCDC8', 'GFRA2', 'MIR654') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'CCDC8', 'GFRA2', 'MIR654') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('FOXD2', 'CCDC8', 'GFRA2', 'MIR654') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('POU3F3', 'CCDC8', 'GFRA2', 'MIR654') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('ALX1', 'CCDC8', 'GFRA2', 'MIR654') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXD2', 'CCDC8', 'GFRA2', 'MIR654') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('POU3F3', 'CCDC8', 'GFRA2', 'MIR654') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('ALX1', 'CCDC8', 'GFRA2', 'MIR654') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('FOXD2', 'CCDC8', 'GFRA2', 'MIR654') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('POU3F3', 'CCDC8', 'GFRA2', 'MIR654') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('ALX1', 'CCDC8', 'GFRA2', 'MIR654') with estimator: Voting\n",
      "INFO Training for combination: ('FOXD2', 'CCDC8', 'GFRA2', 'MIR654') with estimator: Voting\n",
      "INFO Training for combination: ('POU3F3', 'CCDC8', 'GFRA2', 'MIR654') with estimator: Voting\n"
     ]
    }
   ],
   "source": [
    "from utils.simple_model import SimpleModel\n",
    "\n",
    "for model_name, gene_list in selected_feature.items():\n",
    "    for model_name, model_config in models.items():\n",
    "        model = SimpleModel(\n",
    "            train_df=train,\n",
    "            test_df=test,\n",
    "            gene_list=gene_list,\n",
    "            dbeta_info=dbeta_file,\n",
    "        )\n",
    "        model.setup_dbeta()\n",
    "        model.setup_train_test(\"ID_TCGA\")\n",
    "        model.setup_combinations()\n",
    "        model.train(\n",
    "            model_name,\n",
    "            model_config[\"model\"],\n",
    "            train_out_path,\n",
    "            validate_out_path,\n",
    "            model_config[\"is_grid_search\"],\n",
    "            \"ID_TCGA\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_helper import set_parameters\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import json\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "with open(training_param_file, \"r\") as f:\n",
    "    training_param = json.load(f)\n",
    "\n",
    "xgb_grid = set_parameters(XGBClassifier(random_state=42), training_param[\"XGBoost\"])\n",
    "rf_grid = set_parameters(RandomForestClassifier(random_state=42), training_param[\"RandomForest\"])\n",
    "svm_grid = set_parameters(SVC(random_state=42, probability=True), training_param[\"SVM\"])\n",
    "dt_grid = set_parameters(DecisionTreeClassifier(random_state=42), training_param[\"DecisionTree\"])\n",
    "lr_grid = set_parameters(LogisticRegression(random_state=42), training_param[\"LogisticRegression\"])\n",
    "lr_elastic_grid = set_parameters(LogisticRegression(random_state=42), training_param[\"LogisticRegressionElastic\"])\n",
    "voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"XGBoost\", XGBClassifier(random_state=42, n_estimators=50)), \n",
    "        (\"RandomForest\", RandomForestClassifier(random_state=42, n_estimators=50)),\n",
    "        (\"SVM\", SVC(random_state=42, probability=True)),\n",
    "        (\"DecisionTree\", DecisionTreeClassifier(random_state=42, max_depth=5)),\n",
    "        (\"LogisticRegression\", LogisticRegression(random_state=42, C=0.1)),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "\n",
    "# comment out the model you don't want to use\n",
    "models = {\n",
    "    \"XGBoost\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": xgb_grid,\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": rf_grid,\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": svm_grid,\n",
    "    },\n",
    "    \"DecisionTree\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": dt_grid,\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": lr_grid,\n",
    "    },\n",
    "    \"LogisticRegressionElastic\": {\n",
    "        \"is_grid_search\": True,\n",
    "        \"model\": lr_elastic_grid,\n",
    "    },\n",
    "    \"Voting\": {\n",
    "        \"is_grid_search\": False,\n",
    "        \"model\": voting,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO Training for combination: ('DBC1', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('DEGS1', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('DBC1', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('DEGS1', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('DBC1', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('DEGS1', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('DBC1', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('DEGS1', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('DBC1', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('DEGS1', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('DBC1', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('DEGS1', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('DBC1', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: Voting\n",
      "INFO Training for combination: ('DEGS1', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: Voting\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: Voting\n",
      "INFO Training for combination: ('CA3', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('NID2', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('TRIM59', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('CA3', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('NID2', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('TRIM59', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('CA3', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('NID2', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('TRIM59', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('CA3', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('NID2', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('TRIM59', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('CA3', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('NID2', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('TRIM59', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('CA3', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('NID2', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('TRIM59', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: LogisticRegressionElastic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repo\\btc\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repo\\btc\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO Training for combination: ('CA3', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: Voting\n",
      "INFO Training for combination: ('NID2', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: Voting\n",
      "INFO Training for combination: ('TRIM59', 'MIR654', 'PRLHR', 'ZSCAN18') with estimator: Voting\n",
      "INFO Training for combination: ('DGKI', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('HMGCL', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('DGKI', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('HMGCL', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('DGKI', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('HMGCL', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('DGKI', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('HMGCL', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('DGKI', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('HMGCL', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('DGKI', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('HMGCL', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('DGKI', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: Voting\n",
      "INFO Training for combination: ('HMGCL', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: Voting\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'GRIK3', 'MIR129-2') with estimator: Voting\n",
      "INFO Training for combination: ('DGKI', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('SUB1', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('DGKI', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('SUB1', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('DGKI', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('SUB1', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('DGKI', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('SUB1', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('DGKI', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('SUB1', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('DGKI', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('SUB1', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('DGKI', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: Voting\n",
      "INFO Training for combination: ('SUB1', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: Voting\n",
      "INFO Training for combination: ('TRIM59', 'FOXB2', 'KCNK2', 'MIR124-2') with estimator: Voting\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'NID2', 'PRLHR') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'SUB1', 'PRLHR') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'TRIM59', 'PRLHR') with estimator: XGBoost\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'NID2', 'PRLHR') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'SUB1', 'PRLHR') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'TRIM59', 'PRLHR') with estimator: RandomForest\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'NID2', 'PRLHR') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'SUB1', 'PRLHR') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'TRIM59', 'PRLHR') with estimator: SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'NID2', 'PRLHR') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'SUB1', 'PRLHR') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'TRIM59', 'PRLHR') with estimator: DecisionTree\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'NID2', 'PRLHR') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'SUB1', 'PRLHR') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'TRIM59', 'PRLHR') with estimator: LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'NID2', 'PRLHR') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'SUB1', 'PRLHR') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'TRIM59', 'PRLHR') with estimator: LogisticRegressionElastic\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'NID2', 'PRLHR') with estimator: Voting\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'SUB1', 'PRLHR') with estimator: Voting\n",
      "INFO Training for combination: ('FOXB2', 'MIR124-2', 'TRIM59', 'PRLHR') with estimator: Voting\n"
     ]
    }
   ],
   "source": [
    "from utils.simple_model import SimpleModel\n",
    "\n",
    "for model_name, gene_list in selected_feature_2.items():\n",
    "    for model_name, model_config in models.items():\n",
    "        model = SimpleModel(\n",
    "            train_df=train,\n",
    "            test_df=test,\n",
    "            gene_list=gene_list,\n",
    "            dbeta_info=dbeta_file,\n",
    "        )\n",
    "        model.setup_dbeta()\n",
    "        model.setup_train_test(\"ID_GEO\")\n",
    "        model.setup_combinations()\n",
    "        model.train(\n",
    "            model_name,\n",
    "            model_config[\"model\"],\n",
    "            train_out_path,\n",
    "            validate_out_path,\n",
    "            model_config[\"is_grid_search\"],\n",
    "            \"ID_GEO\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator_name</th>\n",
       "      <th>gene_0</th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>fbeta2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Voting</td>\n",
       "      <td>FOXD2</td>\n",
       "      <td>FRZB</td>\n",
       "      <td>GFRA2</td>\n",
       "      <td>MIR1197</td>\n",
       "      <td>0.996411</td>\n",
       "      <td>0.998621</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>0.997245</td>\n",
       "      <td>0.997932</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.984371</td>\n",
       "      <td>0.998345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Voting</td>\n",
       "      <td>NID2</td>\n",
       "      <td>MIR654</td>\n",
       "      <td>PRLHR</td>\n",
       "      <td>ZSCAN18</td>\n",
       "      <td>0.996411</td>\n",
       "      <td>0.997241</td>\n",
       "      <td>0.990991</td>\n",
       "      <td>0.998619</td>\n",
       "      <td>0.997930</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.984490</td>\n",
       "      <td>0.997517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Voting</td>\n",
       "      <td>ALX1</td>\n",
       "      <td>FRZB</td>\n",
       "      <td>GFRA2</td>\n",
       "      <td>MIR1197</td>\n",
       "      <td>0.995215</td>\n",
       "      <td>0.997241</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>0.997241</td>\n",
       "      <td>0.997241</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.979223</td>\n",
       "      <td>0.997241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Voting</td>\n",
       "      <td>ALX1</td>\n",
       "      <td>CCDC8</td>\n",
       "      <td>GFRA2</td>\n",
       "      <td>MIR654</td>\n",
       "      <td>0.995215</td>\n",
       "      <td>0.995862</td>\n",
       "      <td>0.990991</td>\n",
       "      <td>0.998617</td>\n",
       "      <td>0.997238</td>\n",
       "      <td>0.999789</td>\n",
       "      <td>0.979433</td>\n",
       "      <td>0.996412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Voting</td>\n",
       "      <td>FOXD2</td>\n",
       "      <td>CA3</td>\n",
       "      <td>GFRA2</td>\n",
       "      <td>MIR1197</td>\n",
       "      <td>0.995215</td>\n",
       "      <td>0.995862</td>\n",
       "      <td>0.990991</td>\n",
       "      <td>0.998617</td>\n",
       "      <td>0.997238</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>0.979433</td>\n",
       "      <td>0.996412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimator_name gene_0  gene_1 gene_2   gene_3  accuracy    recall  \\\n",
       "12         Voting  FOXD2    FRZB  GFRA2  MIR1197  0.996411  0.998621   \n",
       "20         Voting   NID2  MIR654  PRLHR  ZSCAN18  0.996411  0.997241   \n",
       "10         Voting   ALX1    FRZB  GFRA2  MIR1197  0.995215  0.997241   \n",
       "13         Voting   ALX1   CCDC8  GFRA2   MIR654  0.995215  0.995862   \n",
       "11         Voting  FOXD2     CA3  GFRA2  MIR1197  0.995215  0.995862   \n",
       "\n",
       "    specificity  precision  f1_score       AUC       MCC  fbeta2_score  \n",
       "12     0.981982   0.997245  0.997932  0.999925  0.984371      0.998345  \n",
       "20     0.990991   0.998619  0.997930  0.999925  0.984490      0.997517  \n",
       "10     0.981982   0.997241  0.997241  0.999901  0.979223      0.997241  \n",
       "13     0.990991   0.998617  0.997238  0.999789  0.979433      0.996412  \n",
       "11     0.990991   0.998617  0.997238  0.999776  0.979433      0.996412  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_voting = pd.read_csv(f\"{train_out_path}/Voting_metrics.csv\")\n",
    "train_voting.sort_values(by=\"f1_score\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator_name</th>\n",
       "      <th>gene_0</th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>fbeta2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Voting</td>\n",
       "      <td>TRIM59</td>\n",
       "      <td>MIR654</td>\n",
       "      <td>PRLHR</td>\n",
       "      <td>ZSCAN18</td>\n",
       "      <td>0.958929</td>\n",
       "      <td>0.989286</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.932644</td>\n",
       "      <td>0.960073</td>\n",
       "      <td>0.993878</td>\n",
       "      <td>0.919693</td>\n",
       "      <td>0.977375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Voting</td>\n",
       "      <td>FOXD2</td>\n",
       "      <td>CA3</td>\n",
       "      <td>GFRA2</td>\n",
       "      <td>MIR1197</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.932414</td>\n",
       "      <td>0.958258</td>\n",
       "      <td>0.991709</td>\n",
       "      <td>0.915940</td>\n",
       "      <td>0.974528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Voting</td>\n",
       "      <td>ALX1</td>\n",
       "      <td>CA3</td>\n",
       "      <td>GFRA2</td>\n",
       "      <td>MIR1197</td>\n",
       "      <td>0.951786</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.931708</td>\n",
       "      <td>0.952748</td>\n",
       "      <td>0.991327</td>\n",
       "      <td>0.904808</td>\n",
       "      <td>0.965947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Voting</td>\n",
       "      <td>FOXD2</td>\n",
       "      <td>ATP5G2</td>\n",
       "      <td>GFRA2</td>\n",
       "      <td>MIR196A2</td>\n",
       "      <td>0.948214</td>\n",
       "      <td>0.967857</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.931248</td>\n",
       "      <td>0.949118</td>\n",
       "      <td>0.984184</td>\n",
       "      <td>0.897303</td>\n",
       "      <td>0.960253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Voting</td>\n",
       "      <td>HMGCL</td>\n",
       "      <td>FOXB2</td>\n",
       "      <td>GRIK3</td>\n",
       "      <td>MIR129-2</td>\n",
       "      <td>0.944643</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.902903</td>\n",
       "      <td>0.947341</td>\n",
       "      <td>0.984821</td>\n",
       "      <td>0.894158</td>\n",
       "      <td>0.976189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimator_name  gene_0  gene_1 gene_2    gene_3  accuracy    recall  \\\n",
       "21         Voting  TRIM59  MIR654  PRLHR   ZSCAN18  0.958929  0.989286   \n",
       "11         Voting   FOXD2     CA3  GFRA2   MIR1197  0.957143  0.985714   \n",
       "9          Voting    ALX1     CA3  GFRA2   MIR1197  0.951786  0.975000   \n",
       "7          Voting   FOXD2  ATP5G2  GFRA2  MIR196A2  0.948214  0.967857   \n",
       "23         Voting   HMGCL   FOXB2  GRIK3  MIR129-2  0.944643  0.996429   \n",
       "\n",
       "    specificity  precision  f1_score       AUC       MCC  fbeta2_score  \n",
       "21     0.928571   0.932644  0.960073  0.993878  0.919693      0.977375  \n",
       "11     0.928571   0.932414  0.958258  0.991709  0.915940      0.974528  \n",
       "9      0.928571   0.931708  0.952748  0.991327  0.904808      0.965947  \n",
       "7      0.928571   0.931248  0.949118  0.984184  0.897303      0.960253  \n",
       "23     0.892857   0.902903  0.947341  0.984821  0.894158      0.976189  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_voting = pd.read_csv(f\"{validate_out_path}/Voting_metrics_avg.csv\")\n",
    "test_voting.sort_values(by=\"f1_score\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Congratulation! You have finished the whole pipelineðŸŽ‰. <br>\n",
    "\n",
    "![title](cat.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
