{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一開始先把all_beta_normalized_train 改為 只保留 |dbeta| > 0.35的版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0         1         2         3         4         5         6  \\\n",
      "0  cg00000957  0.825079  0.825079  0.836188  0.836188  0.855953  0.855953   \n",
      "1  cg00001349  0.690023  0.690023  0.802989  0.802989  0.744400  0.744400   \n",
      "2  cg00001583  0.095879  0.095879  0.030527  0.030527  0.058828  0.058828   \n",
      "3  cg00002028  0.037414  0.037414  0.028130  0.028130  0.036667  0.036667   \n",
      "4  cg00002837  0.393330  0.393330  0.278496  0.278496  0.354795  0.354795   \n",
      "\n",
      "          7         8         9  ...       881       882       883       884  \\\n",
      "0  0.856379  0.856379  0.833668  ...  0.901550  0.901550  0.873928  0.873928   \n",
      "1  0.826541  0.826541  0.683470  ...  0.864090  0.864090  0.878295  0.878295   \n",
      "2  0.103293  0.103293  0.054348  ...  0.788893  0.788893  0.566003  0.566003   \n",
      "3  0.026973  0.026973  0.032372  ...  0.053580  0.053580  0.037539  0.037539   \n",
      "4  0.371494  0.371494  0.372948  ...  0.799111  0.799111  0.654631  0.654631   \n",
      "\n",
      "        885       886       887       888       889       890  \n",
      "0  0.820407  0.820407  0.880965  0.880965  0.866919  0.866919  \n",
      "1  0.699745  0.699745  0.851946  0.851946  0.784683  0.784683  \n",
      "2  0.648568  0.648568  0.755152  0.755152  0.503848  0.503848  \n",
      "3  0.063686  0.063686  0.067983  0.067983  0.053181  0.053181  \n",
      "4  0.785799  0.785799  0.709136  0.709136  0.452765  0.452765  \n",
      "\n",
      "[5 rows x 891 columns]\n",
      "           ID         B    gene\n",
      "0  cg13670057  0.359170    ABL1\n",
      "1  cg10266490  0.398036  ACOT11\n",
      "2  cg10976772  0.355652   ACOT7\n",
      "3  cg18770350  0.375086   ACTN2\n",
      "4  cg09499849  0.372613   ACVR1\n",
      "   Unnamed: 0         1         2         3         4         5         6  \\\n",
      "0  cg03520644  0.229817  0.229817  0.079642  0.079642  0.180363  0.180363   \n",
      "1  cg05047401  0.291908  0.291908  0.030616  0.030616  0.219142  0.219142   \n",
      "2  cg06355129  0.232184  0.232184  0.261523  0.261523  0.176360  0.176360   \n",
      "3  cg07790615  0.029336  0.029336  0.031738  0.031738  0.052790  0.052790   \n",
      "4  cg09106903  0.091505  0.091505  0.066134  0.066134  0.126135  0.126135   \n",
      "\n",
      "          7         8         9  ...       881       882       883       884  \\\n",
      "0  0.182330  0.182330  0.156993  ...  0.787966  0.787966  0.717043  0.717043   \n",
      "1  0.228138  0.228138  0.164601  ...  0.790363  0.790363  0.774816  0.774816   \n",
      "2  0.253273  0.253273  0.083640  ...  0.913858  0.913858  0.757479  0.757479   \n",
      "3  0.075713  0.075713  0.052144  ...  0.793958  0.793958  0.713349  0.713349   \n",
      "4  0.094016  0.094016  0.039025  ...  0.726509  0.726509  0.795497  0.795497   \n",
      "\n",
      "        885       886       887       888       889       890  \n",
      "0  0.732963  0.732963  0.653539  0.653539  0.324511  0.324511  \n",
      "1  0.738141  0.738141  0.780185  0.780185  0.721786  0.721786  \n",
      "2  0.796541  0.796541  0.798998  0.798998  0.744522  0.744522  \n",
      "3  0.809180  0.809180  0.798897  0.798897  0.584788  0.584788  \n",
      "4  0.632736  0.632736  0.779592  0.779592  0.643527  0.643527  \n",
      "\n",
      "[5 rows x 891 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nor = pd.read_csv(\"../champ/all_beta_normalized_train.csv\")\n",
    "bio = pd.read_csv(\"../result/result_max_per_gene_single.csv\")\n",
    "\n",
    "print(nor.head())\n",
    "print(bio.head())\n",
    "\n",
    "df_mix = pd.merge(nor, bio,how='inner',left_on=\"Unnamed: 0\",right_on= \"Unnamed: 0\")\n",
    "\n",
    "result_df = df_mix[nor.columns]\n",
    "\n",
    "print(result_df.head())\n",
    "\n",
    "result_df.to_csv(\"../result/all_beta_normalized_train_035.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拿取train 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_train = pd.read_csv('../result/all_beta_normalized_train_035.csv')\n",
    "\n",
    "normalized_test = pd.read_csv('../result/all_beta_normalized_test_035.csv')\n",
    "\n",
    "normalized_train_c = normalized_train[normalized_train['Unnamed: 0'].isin(normalized_test['Unnamed: 0'])]\n",
    "\n",
    "X_train = normalized_train_c.iloc[:, 1::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將資料作為每個人的特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07964195547395, 0.0306162399185655, 0.261522527187986, 0.0317381601785272, 0.0661343516750564, 0.034124742346744, 0.0612473721093203, 0.0405033425088478, 0.0421166306695464, 0.0441721288116272, 0.0588695788320025, 0.100177409816677, 0.294601927214894, 0.0876644736842105, 0.0261368291683736, 0.0257815419105742, 0.101882377964479, 0.0357238069848041, 0.117163321248563, 0.150895679662803, 0.0335174252523329, 0.0537719125467796, 0.0165824835604689, 0.859179019384265, 0.0384339448601004, 0.111423626135872, 0.0458655804480652, 0.0535502457210642, 0.0518960766303635, 0.0425753840318604, 0.048770424162403, 0.0380732015145141, 0.0406645177287379, 0.18425676467143, 0.0516438973127158, 0.0170070862859525, 0.0338581183611533, 0.0476667780376434, 0.0346178372961647, 0.0306251828733054, 0.0335010891609705, 0.0288745488351745, 0.0267751073745774, 0.0240879120879121, 0.0305685358255452, 0.0302554352318757, 0.12283056860677, 0.0457521374104598, 0.0245553145336226, 0.069061067888735, 0.0980087304909406, 0.0315847801994828, 0.028169014084507, 0.0450879007238883, 0.0220335339638865, 0.0391621930828126, 0.0481785207380539, 0.153952730236349, 0.0213536011581614, 0.0374505494505495, 0.0481653010331315, 0.126820603907638, 0.0987490979071446, 0.0273498355547862, 0.0289408404119372, 0.23508331840172, 0.0364713737272576, 0.219601074031454, 0.0367949807202144, 0.0734282907662083, 0.0211013419713096, 0.0819189227100575, 0.064911575562701, 0.0450970406835285, 0.0646178092986604, 0.0344586185438706, 0.0345258163201598, 0.0900756206919628, 0.0221008673305493, 0.0206026058631922, 0.112275007376807, 0.0551977920883165, 0.14450253845571, 0.0164085971804946, 0.0193292077316831, 0.0619822629373355, 0.135790326313353, 0.061245882000599, 0.0227382346861435, 0.041726618705036, 0.0191960058534906, 0.206801369106768, 0.0258782515419684, 0.0181685287668372, 0.0839042305247546, 0.181347637869377, 0.0539120818357755, 0.0696806759574235, 0.121388603402992, 0.0379705400981997, 0.0443798204577064, 0.0435114503816794, 0.0354526116757268, 0.0483805172554459, 0.01529511119452, 0.0584058941728064, 0.0779524214103653, 0.0978640234538601, 0.0412753336628769, 0.0259722507005673, 0.019222790761997, 0.0406774535006805, 0.165900578821927, 0.0493504371272163, 0.200630914826498, 0.129470452801228, 0.064085335125147, 0.0408871745419479, 0.13511964464823, 0.064390078151546, 0.0185414091470952, 0.434488488013292, 0.0642804967129291, 0.0369838992507572, 0.0529026868996241, 0.0896990740740741, 0.0347750698391292, 0.0896100029770765, 0.250348027842227, 0.0946624803767661, 0.0635049683830172, 0.064567876478845, 0.0666614991085962, 0.165943012211669, 0.0094390145936537, 0.0589318600368324, 0.0243935309973046, 0.0830989876265467, 0.0213824402164427, 0.0653508771929825, 0.0578301736498327, 0.0316756934186772, 0.0572106261859583, 0.0481275025516213, 0.0503319768687085, 0.391625615763547, 0.0450884456153557, 0.108390056229654, 0.0475235109717868, 0.0287545470292742, 0.0152062505250777, 0.0420457339562331, 0.0984477992770572, 0.253034389750506, 0.0298455544733547, 0.153774173424828, 0.828427472818881, 0.018446923671711, 0.138122171945701, 0.0054459352801894, 0.0457369226613847, 0.216140502101067, 0.0356539255689821, 0.0612932060959698, 0.764376042614543, 0.885516083938268, 0.198278002574333, 0.811776059948522, 0.876748073037719, 0.0601623081677523, 0.906117995532095, 0.112626809551404, 0.942175947314211, 0.0332793143777608, 0.19059424970173, 0.0427789431601756, 0.407960528870239, 0.848327918264925, 0.915616064508056, 0.885895461760884, 0.734945901939762, 0.859714090942949, 0.0889712225153707, 0.206117380200286, 0.0322222101708508, 0.918071963516832, 0.891790308519021, 0.879670391559579, 0.0094179637026461, 0.855125974197309, 0.864846375054656, 0.75310198680524, 0.256680625761469, 0.895071846960231, 0.93619406978214, 0.0617030087680523, 0.0415160151097194, 0.113079258839324, 0.0395114034653029, 0.0412232325176248, 0.0928447335137871, 0.0608704496088482, 0.166774838857736, 0.738707003352851, 0.173928547835973, 0.0256609073619618, 0.888606872133488, 0.0662307381204539, 0.0593009852311844, 0.0293124423265135, 0.959203681374451, 0.0647554562903694, 0.730989175973796, 0.0763972195495161, 0.0555341722404974, 0.0562236330121769, 0.0537125957076147, 0.874818351233279, 0.880425858954926, 0.0916505496493006, 0.6911633724572, 0.0402440466829029, 0.0614031907846486, 0.911916162892441, 0.0969265347301089, 0.0240424668887438, 0.0454951324408769, 0.111785721969395, 0.28215198791248, 0.462571332742572, 0.0602345252781746, 0.0698577873789177, 0.0360887091126649, 0.0414218617560627, 0.0366753333677169, 0.0340902995932523, 0.0754934488545391, 0.0704995190038695, 0.109951702842493, 0.0169035700642616, 0.0595204908069317, 0.0266673020951101, 0.0540036163351851, 0.192416820860985, 0.0268020504047365, 0.792170640512675, 0.0600026229043301, 0.944780314238402, 0.764688336257491, 0.0555141468544701, 0.0913718592438597, 0.0294934532599286, 0.887386371719387, 0.0567309833653388, 0.207279268342949, 0.0520696768658476, 0.0609250224622827, 0.883270467983642, 0.0137809952206346, 0.0378590903189686, 0.0281547688090752, 0.0488044999376402, 0.21792562274278, 0.0654957635138437, 0.0835513830861327, 0.855423175830932, 0.043590077351142, 0.050420191170629, 0.0603958743420148, 0.0527147182932604, 0.215188747202253, 0.0440568102867236, 0.73441258658194, 0.0854270518541932, 0.0476572507376397, 0.910480901676318, 0.712743503484383, 0.0500687689823134, 0.0272329392824209, 0.0695663470594737, 0.261158936932691, 0.962579731203774, 0.853065608435696, 0.207881882776254, 0.0360994852328707, 0.0215678788853698, 0.104816724578179, 0.941115508861538, 0.0340663072226054, 0.0896294695780275, 0.0437218474192957, 0.0903700310308585, 0.958420133211596, 0.0870025511592437, 0.0485370399685751, 0.0451598179357716, 0.0295020693081424, 0.914436077131962, 0.959785226832431, 0.0597660133340325, 0.0772331309052992, 0.0433126995635947, 0.0531807622796594, 0.200600444232666, 0.88431767559011, 0.0410739841088487, 0.0642528391779672, 0.0343020722539695, 0.0303473854329416, 0.0261214178892353, 0.886055252777849, 0.0716504333362664, 0.0360278761777088, 0.064995739284244, 0.981671272135877, 0.0356005416867529, 0.829818013623224, 0.0450297577196472, 0.0650970999218047, 0.887308523187032, 0.047941275906896, 0.0397117726832843, 0.198002291485903, 0.901951134323008, 0.154188710721939, 0.202407783535235, 0.0373848523181265, 0.159952595810786, 0.1530399767781, 0.0295743893060717, 0.0935467469542687, 0.0745464375622332, 0.0372700672777949, 0.0316686063689079, 0.0251067268108823, 0.0133413703137174, 0.0500531742920215, 0.0396705543115099, 0.175121440154854, 0.0694149925803204, 0.103095418233763, 0.149540991329393, 0.10477789241971, 0.185913299171861, 0.0314618696836866, 0.863684231039861, 0.045999481869097, 0.0661380506837411, 0.0498163031936879, 0.0703077359218728, 0.0493034333786088, 0.151050310565763, 0.0231041263845357, 0.850881793588797, 0.0967063208207831, 0.144551902315346, 0.0896583230814877, 0.0402331059890219, 0.807625618526191, 0.852007130171331, 0.0463184924989389, 0.0211525083240988, 0.0683466812414597, 0.0321731966936564, 0.0323558866198959, 0.833456238927463, 0.816606603549903, 0.0470594025132614, 0.147826826548748, 0.0770282900970732, 0.802017940998901, 0.0816961436428948, 0.136123815518772, 0.0265784983831318, 0.0315422951369041]\n",
      "<class 'numpy.ndarray'> x\n",
      "<class 'numpy.ndarray'> y\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "\n",
    "for i in range(445):\n",
    "    X = X_train.iloc[:, i]\n",
    "\n",
    "    X = X.values.flatten().tolist()\n",
    "\n",
    "    x.append(X)\n",
    "\n",
    "print(x[1])\n",
    "\n",
    "y = [ (0 if i < 47 else 1)  for i in range(445)]\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "print(type(x),'x')\n",
    "print(type(y),'y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "開始預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集:  1.0\n",
      "測試集:  0.9775280898876404\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 建立 Random Forest Classifier 模型\n",
    "randomForestModel = RandomForestClassifier(n_estimators=100, criterion = 'gini')\n",
    "# 使用訓練資料訓練模型\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y,test_size=0.2,random_state=0)\n",
    "\n",
    "randomForestModel.fit(X_train, y_train)\n",
    "# 使用訓練資料預測分類\n",
    "predicted = randomForestModel.predict(X_train)\n",
    "predicted_t = randomForestModel.predict(X_test)\n",
    "\n",
    "print('訓練集: ',randomForestModel.score(X_train,y_train))\n",
    "print('測試集: ',randomForestModel.score(X_test,y_test))\n",
    "\n",
    "# 預測成功的比例\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將特徵重要程度輸出並匯出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徵重要程度:  [2.18674355e-03 7.54359590e-03 2.22277722e-04 0.00000000e+00\n",
      " 1.54807781e-04 3.41923889e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.13421494e-03 5.60885215e-04 1.39004199e-02\n",
      " 2.38811973e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.81047193e-03 8.59751679e-04 2.20422518e-04 0.00000000e+00\n",
      " 2.06400742e-04 0.00000000e+00 2.94312169e-04 0.00000000e+00\n",
      " 0.00000000e+00 2.73430775e-03 1.13449809e-03 2.19325224e-03\n",
      " 0.00000000e+00 0.00000000e+00 4.85330461e-02 2.70977956e-04\n",
      " 8.08425764e-04 0.00000000e+00 3.42307692e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 3.79561751e-02 5.42141740e-04\n",
      " 8.19169621e-04 9.86696231e-04 0.00000000e+00 0.00000000e+00\n",
      " 2.58495498e-04 0.00000000e+00 3.26950452e-04 0.00000000e+00\n",
      " 3.00675676e-04 0.00000000e+00 0.00000000e+00 2.35738461e-03\n",
      " 0.00000000e+00 3.27076963e-03 0.00000000e+00 0.00000000e+00\n",
      " 8.62107559e-03 5.51617886e-02 2.31610555e-03 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.57625076e-02 0.00000000e+00\n",
      " 0.00000000e+00 3.10239651e-04 0.00000000e+00 0.00000000e+00\n",
      " 2.54376563e-04 0.00000000e+00 4.21223718e-04 2.72019428e-03\n",
      " 0.00000000e+00 0.00000000e+00 3.95481943e-03 1.31474614e-03\n",
      " 3.50464472e-02 0.00000000e+00 1.92432432e-03 4.91143957e-04\n",
      " 0.00000000e+00 0.00000000e+00 7.92398655e-03 0.00000000e+00\n",
      " 0.00000000e+00 1.46636161e-02 9.92273134e-04 3.93055580e-05\n",
      " 7.34368514e-03 6.27518343e-05 7.07050645e-04 1.81697335e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.52255908e-03\n",
      " 0.00000000e+00 0.00000000e+00 2.41364948e-02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 3.47379074e-02 7.44470400e-05\n",
      " 6.46051103e-04 1.47965943e-02 0.00000000e+00 6.46818819e-04\n",
      " 2.69710979e-02 0.00000000e+00 2.41294586e-04 2.30224776e-04\n",
      " 4.99553079e-03 1.45417629e-02 1.92907858e-04 6.80955937e-03\n",
      " 2.57348460e-04 3.01942013e-02 0.00000000e+00 0.00000000e+00\n",
      " 2.86851687e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.12262296e-03 0.00000000e+00 0.00000000e+00 2.45981297e-05\n",
      " 0.00000000e+00 1.83846313e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.75872478e-02 0.00000000e+00 0.00000000e+00\n",
      " 1.11330018e-03 3.63287044e-03 0.00000000e+00 5.07415823e-04\n",
      " 4.53048225e-02 6.88933311e-03 2.51961498e-04 2.57968189e-02\n",
      " 1.01392405e-03 2.01078822e-04 4.94800032e-04 9.66347832e-04\n",
      " 6.60097478e-04 0.00000000e+00 0.00000000e+00 8.40440287e-04\n",
      " 8.11824324e-04 1.43779028e-03 0.00000000e+00 3.23930846e-04\n",
      " 0.00000000e+00 4.15541207e-02 0.00000000e+00 0.00000000e+00\n",
      " 8.38288932e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.52363770e-03 2.71600229e-04 5.99791630e-03 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.29931382e-03 4.65533346e-04\n",
      " 0.00000000e+00 4.08517149e-04 9.47076866e-03 0.00000000e+00\n",
      " 3.39168751e-04 1.76419942e-02 0.00000000e+00 3.46487430e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.79385847e-03\n",
      " 0.00000000e+00 1.69584375e-04 0.00000000e+00 7.14165964e-04\n",
      " 2.87998631e-03 8.94696726e-03 6.94118112e-03 0.00000000e+00\n",
      " 8.44642911e-04 1.11305655e-03 0.00000000e+00 0.00000000e+00\n",
      " 2.16103341e-04 0.00000000e+00 0.00000000e+00 3.45154729e-02\n",
      " 0.00000000e+00 0.00000000e+00 6.86195067e-03 1.63242639e-05\n",
      " 2.63915954e-04 0.00000000e+00 1.03407736e-02 0.00000000e+00\n",
      " 2.44486584e-02 1.71843250e-02 0.00000000e+00 0.00000000e+00\n",
      " 1.40180006e-03 5.79781071e-04 7.43540117e-03 0.00000000e+00\n",
      " 5.80359689e-03 0.00000000e+00 9.80887737e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 3.03765399e-05 1.31491190e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.87237027e-04 1.87763713e-04\n",
      " 4.70908519e-04 2.40800866e-04 0.00000000e+00 8.29450140e-04\n",
      " 2.31770833e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.79961581e-04 2.02949370e-02 2.48846638e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.26076768e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.41571390e-03 2.28938907e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.18507157e-04\n",
      " 3.38078461e-04 7.48624817e-03 0.00000000e+00 5.47494433e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.71965940e-02 6.27628448e-05 2.46097936e-03 0.00000000e+00\n",
      " 3.08065074e-04 0.00000000e+00 0.00000000e+00 2.48723751e-04\n",
      " 1.84241234e-03 6.75965734e-03 0.00000000e+00 2.98212246e-05\n",
      " 0.00000000e+00 8.47988381e-04 0.00000000e+00 6.84079303e-04\n",
      " 0.00000000e+00 0.00000000e+00 2.41329022e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 9.74501011e-03 0.00000000e+00 0.00000000e+00\n",
      " 1.83765647e-04 2.64880952e-04 0.00000000e+00 2.16782365e-04\n",
      " 1.06130242e-03 0.00000000e+00 7.27467784e-04 0.00000000e+00\n",
      " 4.64533640e-04 0.00000000e+00 1.89164162e-03 0.00000000e+00\n",
      " 2.65143992e-04 0.00000000e+00 1.06253231e-03 7.91689101e-04\n",
      " 3.37508272e-02 0.00000000e+00 0.00000000e+00 1.13681008e-02\n",
      " 0.00000000e+00 2.10083368e-03 6.35306905e-04 1.33706437e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.92831994e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.16935994e-04 0.00000000e+00 9.64769648e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.21884344e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 9.85860360e-03 1.32253511e-04 4.53440608e-04\n",
      " 0.00000000e+00 0.00000000e+00 9.13258599e-03 9.47577608e-03\n",
      " 0.00000000e+00 7.34393219e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.71188274e-03 2.39680847e-02 0.00000000e+00\n",
      " 1.90782422e-04 0.00000000e+00 1.20690081e-03 0.00000000e+00\n",
      " 5.05036175e-04 0.00000000e+00 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('特徵重要程度: ',randomForestModel.feature_importances_)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Probe_ID': normalized_train['Unnamed: 0'],\n",
    "    'import_level_in_forest': randomForestModel.feature_importances_\n",
    "})\n",
    "\n",
    "# print(df)\n",
    "\n",
    "df.to_csv(\"../result/imp_level.csv\",index=False)"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用cross validation 並拓展多棵樹(100~1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "randomForestModel = RandomForestClassifier(n_estimators=100, criterion = 'gini')\n",
    "\n",
    "scores = cross_val_score(randomForestModel,x,y,cv=5,scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "k_range = range(100,1100,100)\n",
    "rf_score_n_estimators = []\n",
    "\n",
    "for i in range(100,1100,100):\n",
    "    randomForestModel = RandomForestClassifier(n_estimators=i, criterion = 'gini')\n",
    "    scores = cross_val_score(randomForestModel,x,y,cv=5,scoring='accuracy')\n",
    "    rf_score_n_estimators.append(scores.mean())\n",
    "\n",
    "plt.plot(k_range,rf_score_n_estimators)\n",
    "plt.ylim(0.98,1.0)\n",
    "plt.xlabel('RandomForest estimators value')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.xticks(k_range)\n",
    "plt.title('use cross vaildation to find best value estimators')\n",
    "plt.show()"
   ]
=======
>>>>>>> master
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
